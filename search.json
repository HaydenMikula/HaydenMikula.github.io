[
  {
    "objectID": "seaborn_basics.html",
    "href": "seaborn_basics.html",
    "title": "Seaborn Example",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Sample data\ndata = {\n    'Category': ['A', 'B', 'C', 'D'],\n    'Values': [23, 45, 56, 78]\n}\ndf = pd.DataFrame(data)\n\n# Create a barplot\nsns.set(style=\"whitegrid\")  # Optional: Set a clean grid style\nplt.figure(figsize=(8, 6))  # Set the figure size\nsns.barplot(data=df, x='Category', y='Values', palette='viridis')\n\n# Customize the plot\nplt.title(\"Bar Plot Example\", fontsize=16)\nplt.xlabel(\"Category\", fontsize=12)\nplt.ylabel(\"Values\", fontsize=12)\n\n# Show the plot\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(data=df, x='Category', y='Values', palette='viridis')"
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let’s analyze the starwars data:\nstarwars &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs. Droid",
    "text": "Human vs. Droid\n\nggplot(data = \n         starwars %&gt;% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code with no space in the folder name.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hayden Mikula",
    "section": "",
    "text": "Hayden Mikula majors in Data Analytics at SUNY Geneseo."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Hayden Mikula",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo | Geneseo, NY  B.S. in Data Analytics | Aug 2022 - May 2026  Minor in Edgar Fellows Honors Program"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Hayden Mikula",
    "section": "Experience",
    "text": "Experience\nStarbucks Analytics | Data Analyst Intern | May 2024 - Aug 2024"
  },
  {
    "objectID": "danl-310-quarto-r.html",
    "href": "danl-310-quarto-r.html",
    "title": "Quarto with R",
    "section": "",
    "text": "“Tidy datasets are all alike, but every messy dataset is messy in its own way.” — Hadley Wickham\n\nR is a powerful language and environment for statistical computing and graphics. It is widely used among statisticians and data analysts for data analysis and developing statistical software. Here are some basic concepts and elements of R to help you get started:\n\n\n\nVariables in R are used to store data. You can create a variable using the assignment operator &lt;- (option/Alt + -). For example:\n\n\nCode\nmy_variable &lt;- 10\n\n\nThis will store the value 10 in my_variable.\n\n\n\n\n\nR has several basic data types:\n\nNumeric: For decimal values like 2.5.\nInteger: For whole numbers like 2L (the L tells R it is an integer).\nCharacter: For text or string values, e.g., \"Hello\".\nLogical: For boolean values (TRUE or FALSE).\n\n\n\n\n\n\nVectors are a basic data structure in R. They contain elements of the same type. You can create a vector using the c() function:\n\n\nCode\nmy_vector &lt;- c(1, 2, 3, 4, 5)\n\n\n\n\n\n\nData frames are used for storing data tables in R. It is a list of vectors of equal length. For example, to create a simple data frame:\n\n\nCode\ndf &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\"), \n  Age = c(25, 30)\n  )\n\n\n\n\n\n\nFunctions are used to carry out specific tasks in R. For example, sum() is a function that adds numbers together:\n\n\nCode\nsum(1, 2, 3) # Returns 6\n\n\n[1] 6\n\n\n\n\n\n\nR has a vast collection of packages for various statistical tasks. You can install a package using install.packages(\"packageName\") and load it using library(packageName).\n\n\nCode\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n\n\n\n\n\nTo get help on a specific function or topic, use the help() function or the shorthand ?, like ?sum on R Console."
  },
  {
    "objectID": "danl-310-quarto-r.html#variables",
    "href": "danl-310-quarto-r.html#variables",
    "title": "Quarto with R",
    "section": "",
    "text": "Variables in R are used to store data. You can create a variable using the assignment operator &lt;- (option/Alt + -). For example:\n\n\nCode\nmy_variable &lt;- 10\n\n\nThis will store the value 10 in my_variable."
  },
  {
    "objectID": "danl-310-quarto-r.html#data-types",
    "href": "danl-310-quarto-r.html#data-types",
    "title": "Quarto with R",
    "section": "",
    "text": "R has several basic data types:\n\nNumeric: For decimal values like 2.5.\nInteger: For whole numbers like 2L (the L tells R it is an integer).\nCharacter: For text or string values, e.g., \"Hello\".\nLogical: For boolean values (TRUE or FALSE)."
  },
  {
    "objectID": "danl-310-quarto-r.html#vectors",
    "href": "danl-310-quarto-r.html#vectors",
    "title": "Quarto with R",
    "section": "",
    "text": "Vectors are a basic data structure in R. They contain elements of the same type. You can create a vector using the c() function:\n\n\nCode\nmy_vector &lt;- c(1, 2, 3, 4, 5)"
  },
  {
    "objectID": "danl-310-quarto-r.html#data-frames",
    "href": "danl-310-quarto-r.html#data-frames",
    "title": "Quarto with R",
    "section": "",
    "text": "Data frames are used for storing data tables in R. It is a list of vectors of equal length. For example, to create a simple data frame:\n\n\nCode\ndf &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\"), \n  Age = c(25, 30)\n  )"
  },
  {
    "objectID": "danl-310-quarto-r.html#functions",
    "href": "danl-310-quarto-r.html#functions",
    "title": "Quarto with R",
    "section": "",
    "text": "Functions are used to carry out specific tasks in R. For example, sum() is a function that adds numbers together:\n\n\nCode\nsum(1, 2, 3) # Returns 6\n\n\n[1] 6"
  },
  {
    "objectID": "danl-310-quarto-r.html#packages",
    "href": "danl-310-quarto-r.html#packages",
    "title": "Quarto with R",
    "section": "",
    "text": "R has a vast collection of packages for various statistical tasks. You can install a package using install.packages(\"packageName\") and load it using library(packageName).\n\n\nCode\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)"
  },
  {
    "objectID": "danl-310-quarto-r.html#help-system",
    "href": "danl-310-quarto-r.html#help-system",
    "title": "Quarto with R",
    "section": "",
    "text": "To get help on a specific function or topic, use the help() function or the shorthand ?, like ?sum on R Console."
  },
  {
    "objectID": "danl-310-quarto-r.html#key-concepts",
    "href": "danl-310-quarto-r.html#key-concepts",
    "title": "Quarto with R",
    "section": "2.1 Key Concepts",
    "text": "2.1 Key Concepts\n\nData: The raw data that you want to plot.\naes() (Aesthetic Mappings): Defines how data are mapped to color, size, shape, and other visual properties.\nGeoms (Geometric Objects): The type of objects that represent data points, like points, lines, bars, etc.\nFacets: For creating small multiples, splitting data into subsets and displaying the same plot for each subset.\nScales: Control how data values are translated to visual properties.\nCoordinate Systems: The plane in which data is plotted, e.g., Cartesian, polar.\nThemes: Control the overall appearance of the plot, like background color, grid lines, and font sizes."
  },
  {
    "objectID": "danl-310-quarto-r.html#examples",
    "href": "danl-310-quarto-r.html#examples",
    "title": "Quarto with R",
    "section": "2.2 Examples",
    "text": "2.2 Examples\nLet’s go through some examples to illustrate how ggplot can be used to create different types of visualizations.\n\n2.2.1 Scatter Plot\nCreating a scatter plot to explore the relationship between two variables, say mpg (miles per gallon) and wt (weight of the car) from the mtcars dataset.\n\n\nCode\nggplot(mtcars, aes(x = wt, y = mpg)) + \n  geom_point() +\n  labs(x = \"Weight of Car\", y = \"Miles Per Gallon\",\n       title = \"Scatter plot of MPG vs Car Weight\")\n\n\n\n\n\n\n\n\n\nThis code block creates a scatter plot where car weight is on the x-axis and miles per gallon on the y-axis. Each point represents a car.\n\n\n2.2.2 Bar Chart\nCreating a bar chart to show the count of cars by the number of cylinders.\n\n\nCode\nggplot(mtcars, aes(x = factor(cyl))) + \n  geom_bar() + \n  labs(x = \"Number of Cylinders\", y = \"Count\",\n       title = \"Count of Cars by Cylinders\")\n\n\n\n\n\n\n\n\n\nThis plots a bar chart where each bar represents the count of cars with a certain number of cylinders.\n\n\n2.2.3 Line Graph\nPlotting a line graph, assuming we have a time series data.frame economics that is part of ggplot2 package.\n\n\nCode\nggplot(economics, aes(x = date, y = unemploy)) + \n  geom_line() +\n  labs(x = \"Year\", y = \"Number of Unemployed Persons\",\n       title = \"Unemployment over Time\") \n\n\n\n\n\n\n\n\n\nThis code plots the unemployment numbers over time, with time on the x-axis and the number of unemployed persons on the y-axis.\n\n\n2.2.4 Faceted Plot\nCreating a faceted plot to compare scatter plots of mpg vs wt across different numbers of cylinders.\n\n\nCode\nggplot(mtcars, aes(x = wt, y = mpg)) + \n  geom_point() +\n  facet_wrap(~cyl) +\n  labs(title = \"MPG vs Weight by Number of Cylinders\")\n\n\n\n\n\n\n\n\n\nThis splits the data into subsets based on the number of cylinders and creates a scatter plot for each subset."
  },
  {
    "objectID": "danl-310-quarto-r.html#conclusion",
    "href": "danl-310-quarto-r.html#conclusion",
    "title": "Quarto with R",
    "section": "2.3 Conclusion",
    "text": "2.3 Conclusion\nggplot2 provides a powerful and flexible system for making a wide variety of plots. By understanding the grammar of graphics upon which it is based, you can build up complex visualizations from simple components, allowing for a deep and intuitive exploration of data."
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Insightful Analytics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nNYC Dog Breed Blog\n\n\n\n\n\n\n\n\nApr 5, 2025\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nBen & Jerry’s Blog\n\n\n\n\n\n\n\n\nMar 24, 2025\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nSpotify Favorites Analysis\n\n\n\n\n\n\n\n\nMar 2, 2025\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nggplot Basics\n\n\n\n\n\n\n\n\nFeb 18, 2025\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nPython Basics\n\n\n\n\n\n\n\n\nFeb 17, 2025\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\nJan 22, 2025\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nStarwars\n\n\n\n\n\n\n\n\nJan 22, 2025\n\n\nYour Name\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\nJan 22, 2025\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "danl_proj_nba.html#salary-distribution-among-teams",
    "href": "danl_proj_nba.html#salary-distribution-among-teams",
    "title": "Data Analysis Project",
    "section": "Salary Distribution Among Teams",
    "text": "Salary Distribution Among Teams\nLet’s start with the salary distribution among teams using seaborn for visualization. ​​\n\n\n# Handle missing values in 'Salary' by replacing them with the median salary\nmedian_salary = nba['Salary'].median()\nnba['Salary'].fillna(median_salary, inplace=True)\n\n/var/folders/_m/d6jf0jhd2zzdfd5kzdhl_24w0000gn/T/ipykernel_79892/1671011424.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  nba['Salary'].fillna(median_salary, inplace=True)\n\n\n\n# Set the aesthetic style of the plots\nsns.set_style(\"whitegrid\")\n\n# Calculate total salary by team\nteam_salary = (\n    nba\n    .groupby('Team')['Salary']\n    .sum()\n    .reset_index()\n    .sort_values(by='Salary', ascending=False)\n)\n\n# Plot total salary by team\nplt.figure(figsize=(10, 16))\nsns.barplot(data = team_salary,\n            x = 'Salary', y = 'Team',\n            palette = 'coolwarm')\nplt.title('Total Salary Distribution Among NBA Teams')\nplt.xlabel('Total Salary')\nplt.ylabel('Team')\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\nThe visualization above displays the total salary distribution among NBA teams, with teams sorted by their total salary expenditure. This bar plot reveals which teams are the biggest spenders on player salaries and which are more conservative. The color gradient provides a visual cue to easily distinguish between the higher and lower spending teams.\nNotice that Portland Trail Blazers has the highest total salary followed by Golden State Warriors and Philadelphia 76ers, and Memphis Grizzlies has the lowest total salary."
  },
  {
    "objectID": "danl_proj_nba.html#player-age-distribution",
    "href": "danl_proj_nba.html#player-age-distribution",
    "title": "Data Analysis Project",
    "section": "Player Age Distribution",
    "text": "Player Age Distribution\nNext, let’s explore the Player Age Distribution across the NBA. We’ll create a histogram to visualize how player ages are distributed, which will help us understand if the league trends younger, older, or has a balanced age mix. ​​\n\n# Convert 'Birthday' column to datetime format\nfrom dateutil import parser\n# nba['Birthday'] = nba['Birthday'].apply(lambda x: parser.parse(x))\n\n# Now, let's calculate the age of each player\n# nba['Age'] = (datetime.now() - nba['Birthday']).dt.days // 365\n\n# Plot the age distribution of NBA players\nplt.figure(figsize=(10, 6))\nsns.histplot(nba['Age'],\n             bins = 15,\n             kde = True,\n             color = 'skyblue')\nplt.title('Age Distribution of NBA Players')\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.show()\n\n\n/Users/bchoe/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n\n\n\n\n\n\n\n\n\nThe histogram above shows the age distribution of NBA players, with a kernel density estimate (KDE) overlay to indicate the distribution shape. The plot helps identify the common ages for NBA players and whether there are significant numbers of very young or older players.\nNotice that the majority of players fall within an age range from 24 to 34. There are few players whose age is above 40."
  },
  {
    "objectID": "danl_proj_nba.html#position-wise-salary-insights",
    "href": "danl_proj_nba.html#position-wise-salary-insights",
    "title": "Data Analysis Project",
    "section": "Position-wise Salary Insights",
    "text": "Position-wise Salary Insights\nMoving on to Position-wise Salary Insights, we’ll examine how average salaries differ across player positions. This analysis could reveal which positions are typically higher-paid, potentially reflecting their value on the basketball court. Let’s create a box plot to visualize the salary distribution for each position. ​​\n\n# Plot salary distribution by player position\nplt.figure(figsize=(10, 6))\nsns.boxplot(data = nba,\n            x = 'Position', y = 'Salary',\n            palette = 'Set2')\nplt.title('Salary Distribution by Position')\nplt.xlabel('Position')\nplt.ylabel('Salary')\nplt.show()\n\n\n\n\n\n\n\n\nThe box plot above illustrates the salary distribution by player position, showcasing the variation in salaries among different positions within the NBA. PG-SG has the highest median salary."
  },
  {
    "objectID": "danl_proj_nba.html#top-10-highest-paid-players",
    "href": "danl_proj_nba.html#top-10-highest-paid-players",
    "title": "Data Analysis Project",
    "section": "Top 10 Highest Paid Players",
    "text": "Top 10 Highest Paid Players\nLastly, we’ll identify the Top 10 Highest Paid Players in the NBA. Let’s visualize this information.\n\n# Identify the top 10 highest paid players\ntop_10_salaries = nba.sort_values(by='Salary', ascending=False).head(10)\n\n# Plot the top 10 highest paid players\nplt.figure(figsize=(12, 8))\nsns.barplot(data = top_10_salaries,\n            x = 'Salary', y = 'PlayerName',\n            palette = 'viridis')\nplt.title('Top 10 Highest Paid NBA Players')\nplt.xlabel('Salary')\nplt.ylabel('Player')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar plot above reveals the top 10 highest-paid NBA players, showcasing those who stand at the pinnacle of the league in terms of salary. This visualization not only highlights the star players who command the highest salaries but also may reflect their marketability, performance, and contribution to their respective teams."
  },
  {
    "objectID": "pandas_basics.html#creating-a-series",
    "href": "pandas_basics.html#creating-a-series",
    "title": "Pandas Basics",
    "section": "Creating a Series",
    "text": "Creating a Series\n\n\n# Creating a Series from a list\ndata = [10, 20, 30, 40, 50]\nseries = pd.Series(data)\nseries\n\n\n\n\n\n\n\n\n0\n\n\n\n\n0\n10\n\n\n1\n20\n\n\n2\n30\n\n\n3\n40\n\n\n4\n50\n\n\n\n\ndtype: int64"
  },
  {
    "objectID": "pandas_basics.html#creating-a-dataframe",
    "href": "pandas_basics.html#creating-a-dataframe",
    "title": "Pandas Basics",
    "section": "Creating a DataFrame",
    "text": "Creating a DataFrame\n\n\n# Creating a DataFrame from a dictionary\ndata = {\n    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"Age\": [25, 30, 35],\n    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n}\ndf = pd.DataFrame(data)\ndf\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n0\nAlice\n25\nNew York\n\n\n1\nBob\n30\nLos Angeles\n\n\n2\nCharlie\n35\nChicago"
  },
  {
    "objectID": "pandas_basics.html#exploring-data",
    "href": "pandas_basics.html#exploring-data",
    "title": "Pandas Basics",
    "section": "Exploring Data",
    "text": "Exploring Data\n\n\n# Display the first few rows\ndf.head()\n\n# Display the shape of the DataFrame\nprint(\"Shape:\", df.shape)\n\n# Display summary statistics\ndf.describe()\n\nShape: (3, 3)\n\n\n\n  \n    \n\n\n\n\n\n\nAge\n\n\n\n\ncount\n3.0\n\n\nmean\n30.0\n\n\nstd\n5.0\n\n\nmin\n25.0\n\n\n25%\n27.5\n\n\n50%\n30.0\n\n\n75%\n32.5\n\n\nmax\n35.0"
  },
  {
    "objectID": "pandas_basics.html#selecting-data",
    "href": "pandas_basics.html#selecting-data",
    "title": "Pandas Basics",
    "section": "Selecting Data",
    "text": "Selecting Data\n\n# Selecting a single column\ndf[\"Name\"]\n\n\n\n\n\n\n\n\nName\n\n\n\n\n0\nAlice\n\n\n1\nBob\n\n\n2\nCharlie\n\n\n\n\ndtype: object\n\n\n\n# Selecting multiple columns\ndf[[\"Name\", \"City\"]]\n\n\n  \n    \n\n\n\n\n\n\nName\nCity\n\n\n\n\n0\nAlice\nNew York\n\n\n1\nBob\nLos Angeles\n\n\n2\nCharlie\nChicago\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n# Selecting rows by index\ndf.iloc[0]\n\n\n\n\n\n\n\n\n0\n\n\n\n\nName\nAlice\n\n\nAge\n25\n\n\nCity\nNew York\n\n\n\n\ndtype: object"
  },
  {
    "objectID": "pandas_basics.html#filtering-data",
    "href": "pandas_basics.html#filtering-data",
    "title": "Pandas Basics",
    "section": "Filtering Data",
    "text": "Filtering Data\n\n# Filtering rows where Age is greater than 25\nfiltered_df = df[df[\"Age\"] &gt; 25]\nfiltered_df\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n1\nBob\n30\nLos Angeles\n\n\n2\nCharlie\n35\nChicago"
  },
  {
    "objectID": "pandas_basics.html#adding-a-new-column",
    "href": "pandas_basics.html#adding-a-new-column",
    "title": "Pandas Basics",
    "section": "Adding a New Column",
    "text": "Adding a New Column\n\n\n# Adding a new column\ndf[\"Salary\"] = [50000, 60000, 70000]\ndf\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\nSalary\n\n\n\n\n0\nAlice\n25\nNew York\n50000\n\n\n1\nBob\n30\nLos Angeles\n60000\n\n\n2\nCharlie\n35\nChicago\n70000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n    ## Conclusion\n\n    This notebook covers the basic operations of pandas. You can explore more advanced features like merging,\n    joining, and working with time series data in pandas documentation: https://pandas.pydata.org/docs/"
  },
  {
    "objectID": "posts/python_basics/danl-210-python-basic.html",
    "href": "posts/python_basics/danl-210-python-basic.html",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\nprint('Hello, World!')\n\n\n\n\nIn Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\n\nfloat_variable\n\n10.5\n\n\n\n\n\nPython supports the usual logical conditions from mathematics:\n\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b\n\nThese conditions can be used in several ways, most commonly in ‘if statements’ and loops.\n\n# if statement:\nif 5 &gt; 2:\n    print('Five is greater than two!')\n\n\n\n\nA function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()\n\n\n\n\nA list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\n\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}"
  },
  {
    "objectID": "posts/python_basics/danl-210-python-basic.html#what-is-python",
    "href": "posts/python_basics/danl-210-python-basic.html#what-is-python",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\nprint('Hello, World!')"
  },
  {
    "objectID": "posts/python_basics/danl-210-python-basic.html#variables-and-data-types",
    "href": "posts/python_basics/danl-210-python-basic.html#variables-and-data-types",
    "title": "Python Basics",
    "section": "",
    "text": "In Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\n\nfloat_variable\n\n10.5"
  },
  {
    "objectID": "posts/python_basics/danl-210-python-basic.html#control-structures",
    "href": "posts/python_basics/danl-210-python-basic.html#control-structures",
    "title": "Python Basics",
    "section": "",
    "text": "Python supports the usual logical conditions from mathematics:\n\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b\n\nThese conditions can be used in several ways, most commonly in ‘if statements’ and loops.\n\n# if statement:\nif 5 &gt; 2:\n    print('Five is greater than two!')"
  },
  {
    "objectID": "posts/python_basics/danl-210-python-basic.html#functions",
    "href": "posts/python_basics/danl-210-python-basic.html#functions",
    "title": "Python Basics",
    "section": "",
    "text": "A function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()"
  },
  {
    "objectID": "posts/python_basics/danl-210-python-basic.html#lists-and-dictionaries",
    "href": "posts/python_basics/danl-210-python-basic.html#lists-and-dictionaries",
    "title": "Python Basics",
    "section": "",
    "text": "A list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\n\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html",
    "href": "posts/python_basics/python_basics_4&5.html",
    "title": "Python Basics",
    "section": "",
    "text": "A ‘value’ in Python is any amount of data, no matter what type\nExamples of values:\n\n10 #Integer\n'Hello' # String\n5.71 # Float\nTrue # Bool\n\nWhen these values are assigned to a data container, they become ‘variables’\nVariables are capable of storing one or more values for use in data collection, transformation, etc.\n\na = 10 # 'a' is the name of the variable\nprint(a)\nexample_list = [20, 9, True, 'string']\n\n10"
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html#values-variables-and-types",
    "href": "posts/python_basics/python_basics_4&5.html#values-variables-and-types",
    "title": "Python Basics",
    "section": "",
    "text": "A ‘value’ in Python is any amount of data, no matter what type\nExamples of values:\n\n10 #Integer\n'Hello' # String\n5.71 # Float\nTrue # Bool\n\nWhen these values are assigned to a data container, they become ‘variables’\nVariables are capable of storing one or more values for use in data collection, transformation, etc.\n\na = 10 # 'a' is the name of the variable\nprint(a)\nexample_list = [20, 9, True, 'string']\n\n10"
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html#data-frames",
    "href": "posts/python_basics/python_basics_4&5.html#data-frames",
    "title": "Python Basics",
    "section": "Data Frames",
    "text": "Data Frames\nA ‘data.frame’ is a format of data structure that stores data using observations (rows) and variables (columns). Each individual value corresponds to a ‘cell’, which has meaning based on its associated row index and variable.\nExample:\n\nimport pandas as pd\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\")\nnba\n\n\n  \n    \n\n\n\n\n\n\nName\nTeam\nPosition\nBirthday\nSalary\n\n\n\n\n0\nShake Milton\nPhiladelphia 76ers\nSG\n9/26/96\n1445697\n\n\n1\nChristian Wood\nDetroit Pistons\nPF\n9/27/95\n1645357\n\n\n2\nPJ Washington\nCharlotte Hornets\nPF\n8/23/98\n3831840\n\n\n3\nDerrick Rose\nDetroit Pistons\nPG\n10/4/88\n7317074\n\n\n4\nMarial Shayok\nPhiladelphia 76ers\nG\n7/26/95\n79568\n\n\n...\n...\n...\n...\n...\n...\n\n\n445\nAustin Rivers\nHouston Rockets\nPG\n8/1/92\n2174310\n\n\n446\nHarry Giles\nSacramento Kings\nPF\n4/22/98\n2578800\n\n\n447\nRobin Lopez\nMilwaukee Bucks\nC\n4/1/88\n4767000\n\n\n448\nCollin Sexton\nCleveland Cavaliers\nPG\n1/4/99\n4764960\n\n\n449\nRicky Rubio\nPhoenix Suns\nPG\n10/21/90\n16200000\n\n\n\n\n450 rows × 5 columns"
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html#lists-dictionaries-and-slicing",
    "href": "posts/python_basics/python_basics_4&5.html#lists-dictionaries-and-slicing",
    "title": "Python Basics",
    "section": "Lists, Dictionaries, and Slicing",
    "text": "Lists, Dictionaries, and Slicing\nAs previously shown, a ‘list’ is a data container that works in a singlular series of data (i.e. A single row of values). The values in a list are able to be gathered with [] (see below):\n\nexample_list\n\n[20, 9, True, 'string']\n\n\n\nexample_list[0] # Produces the FIRST value in the list, because Python begins counting at 0 instead of 1\n\n20\n\n\nA ‘dictionary’, in comparison, is a list that utilizes a key-value pair to identify values rather than a numerical index:\n\nexample_dict = {'a' : 10, 'b' : 14, 'c' : 'Hello'}\n  #example_dict[1] would not work, because dictionaries do not have numerical indexes\n\nprint(example_dict.keys())\nprint(example_dict.values())\n\nexample_dict['b']\n\ndict_keys(['a', 'b', 'c'])\ndict_values([10, 14, 'Hello'])\n\n\n14\n\n\nStrings and Lists can be ‘sliced’ with []\n\nFor strings, their characters are sliced\nFor lists, their individual values are sliced\n\nKinds of slicing:\n\n[ _ :]\n\nSlices from the indicated position to the end\n\n[ : _ ]\n\nSlices from the beginning to the indicated position\n\n[ _ : _ ]\n\nSlices from the (left) indicated position to the (right) indicated position\n\nCan add an additional ’: _’ at the end of any of these slicing methods to indicate the ‘step’ of the slicing (eg. A step of ‘2’ = every other value).\n\n\n\n\neg_string = \"Hello, I am a string.\"\nprint(eg_string[4]) # 5th character, starting at 0\n\nprint(example_list[-1]) # Last item in the list\n\nprint(eg_string[3:13]) # Characters starting at position 3 and ending at position 13\n\no\nstring\nlo, I am a"
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html#operators",
    "href": "posts/python_basics/python_basics_4&5.html#operators",
    "title": "Python Basics",
    "section": "Operators",
    "text": "Operators\nPython includes symbols that work as operations that act on data, including:\n\n‘+’ for addition\n‘-’ for subtraction\n’*’ for multiplication\n‘/’ for division\n’**’ for exponents\n‘//’ for integer division\n\nThese operations work on most data types, though some work better than others. For example:\n\nstring_1 = \"My name is\"\nstring_2 = \"Steven\"\nprint(string_1 + \" \" + string_2)\n  #string_1 - string_2 would not work; subtraction is not supported by strings\nprint((string_2 + ' ') * 4)\n\nMy name is Steven\nSteven Steven Steven Steven"
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html#value-conversion",
    "href": "posts/python_basics/python_basics_4&5.html#value-conversion",
    "title": "Python Basics",
    "section": "Value Conversion",
    "text": "Value Conversion\nWe are able to alter a value’s ‘type’ with built-in Python functions, such as:\n\nint()\nfloat()\nstr()\nbool()\n\n\neg_int = int(29.75)\neg_float = float(10)\neg_str = str(92)\neg_bool = bool(0)\n\nprint(eg_int)\nprint(eg_float)\nprint(eg_str)\nprint(eg_bool)\n\n29\n10.0\n92\nFalse"
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html#boolean-conditions",
    "href": "posts/python_basics/python_basics_4&5.html#boolean-conditions",
    "title": "Python Basics",
    "section": "Boolean Conditions",
    "text": "Boolean Conditions\nBoolean conditions are operations which result in a boolean ‘True’ or ‘False’ value, and are used to either filter the data we are looking at or proceed with an action based on the True/False value of the condition.\n\nprint(10 == 20) # False\nprint(20 == '20') # False\n\nFalse\nFalse\n\n\nKinds of conditions (using x/y as placeholders for data):\n\nx and y\n\n“Are both x and y True?”\n\nx or y\n\n“Is either x or y True?”\n\nnot x\n\n“Is x False?”\n\nx in y\n\n“Does x exist within y?”\n\nx == y\n\n“Is x equal to y?”\n\nx != y\n\n“Is x not equal to y?”\n\nx &gt; y\n\n“Is x greater than y?”\n\nx &gt;= y\n\n“Is x greater than or equal to y?”\n\nx &lt; y\n\n“Is x less than y?”\n\nx &lt;= y\n\n“Is x less than or equal to y?”\n\n\n‘if’ statements are lines of code that run when the outlined condition is met\n\nnum = 20\nif num == 20:\n  print('That is correct!')\n\nThat is correct!\n\n\n‘else’ statements are lines of code that are run when the outlined condition of an ‘if’ statement is NOT met\n\nnum = 15\nif num == 20:\n  print('That is correct!')\nelse:\n  print('That is incorrect...')\n\nThat is incorrect...\n\n\n‘elif’ statements are lines of code that are run when the previous ‘if’ or ‘elif’ condition is not met\n\nnum = 0\nif num == 20:\n  print('That is correct!')\nelif 18 &lt;= num &lt; 20:\n  print(\"You're getting closer.\")\nelif num &gt; 20:\n  print('Too far!')\nelse:\n  print(\"Too low!\")\n\nToo low!"
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html#while-and-for-loops",
    "href": "posts/python_basics/python_basics_4&5.html#while-and-for-loops",
    "title": "Python Basics",
    "section": "While and For loops",
    "text": "While and For loops\n\nA ‘while’ loop carries out a set of instructions for as long as a certain condition is met\nA ‘for’ loop iterates on a data container and carries out a set of instructions for as many times as the container is iterated\n\n‘continue’ is used to skip to the end of the loop\n‘break’ is used to stop the loop\n\n\n\ncount = 1\nwhile count &lt;= 5:\n    print(count)\n    count += 1\n\n1\n2\n3\n4\n5\n\n\n\nword = 'thud'\nfor letter in word:\n    print(letter)\n\nt\nh\nu\nd\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\nword = 'thud'\nfor letter in word:\n    if letter == 'u':\n        break # Ends the loop before it can finish fully\n    print(letter)\n\nt\nh\n\n\n\nword = 'thud'\nfor letter in word:\n    if letter == 'u':\n        continue # Skips over the print() function for 'u'\n    print(letter)\n\nt\nh\nd"
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html#list-comprehension",
    "href": "posts/python_basics/python_basics_4&5.html#list-comprehension",
    "title": "Python Basics",
    "section": "List Comprehension",
    "text": "List Comprehension\nA way of creating or filtering list values using conditions\n\nSyntax: listname_new = [ _ for _ in listname_old if ‘condition’ ]\n\n\nnumbers = list(range(1, 21))\nprint(numbers)\n\nevens = [num for num in numbers if num % 2 == 0]\nprint(evens)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]"
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html#dictionary-comprehension",
    "href": "posts/python_basics/python_basics_4&5.html#dictionary-comprehension",
    "title": "Python Basics",
    "section": "Dictionary Comprehension",
    "text": "Dictionary Comprehension\nA way of creating or filtering dictionary keys / values using conditions\n\nSyntax: dictname_new = { k:v for k, v in dictname_old if ‘condition’ }\n\n\n# Filtering\nmy_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\nfiltered_dict = {k: v for k, v in my_dict.items() if v != 2}\nprint(filtered_dict)\n\n# Swapping Values\noriginal_dict = {'a': 1, 'b': 2, 'c': 3}\nswapped_dict = {v: k for k, v in original_dict.items()}\nprint(swapped_dict)\n\n{'a': 1, 'c': 3, 'd': 4}\n{1: 'a', 2: 'b', 3: 'c'}"
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html#list-dictionary-modification",
    "href": "posts/python_basics/python_basics_4&5.html#list-dictionary-modification",
    "title": "Python Basics",
    "section": "List / Dictionary Modification",
    "text": "List / Dictionary Modification\nA method (.__) can be used to modify certain aspects of lists and dictionaries\nLists\n\nlist.append(): Add a new item to the end of the list\nlist. remove(): Remove the FIRST occurrence of the specified value\ndel list[]: Deletes a list’s values by index rather than value\n\nDictionaries:\n\ndict.update({}): Add a new key-value pair or change an existing pair\ndel dict[]: Deletes a dictionary’s key-value pair based on the specified key"
  },
  {
    "objectID": "posts/python_basics/python_basics_4&5.html#try-except",
    "href": "posts/python_basics/python_basics_4&5.html#try-except",
    "title": "Python Basics",
    "section": "Try-Except",
    "text": "Try-Except\nTry-Except code blocks tries to run a block of code, and if an error is raised from attempting to run that code, then an exception is raised instead that is specified by the user.\nFor example:\n\neg_list = [1, 2, 3, 4, 5, 6]\nposition = 9\ntry:\n  print(eg_list[position])\nexcept:\n  print(f\"Invalid position. Expected a value between 0 and {len(eg_list)-1} but got '{position}' instead.\")\n\nInvalid position. Expected a value between 0 and 5 but got '9' instead."
  },
  {
    "objectID": "posts/ggplot_basics/ggplot_basics.html",
    "href": "posts/ggplot_basics/ggplot_basics.html",
    "title": "ggplot Basics",
    "section": "",
    "text": "library(tidyverse)\n\n\nAesthetic Mappings\nIn ggplot, there are certain aesthetics that can be mapped to the data of a visualization. Some of these aesthetics are:\n\nSize (in millimeters)\nShape (from 0 to 25, see below)\nColor\nFill\nAlpha Transparency (from 0 to 1)\n\n\nAesthetics can be mapped uniformly to all data, or split up according to certain categorical observations that exist within the data set.\nThis applies to all aesthetic values that can be altered.\n\n# Uniform\nggplot(data = mpg, aes(x = hwy,\n                       y = displ)) +\n  geom_point(color = \"blue\")\n\n\n\n\n\n\n\n\n\n# Split\nggplot(data = mpg, aes(x = hwy,\n                       y = displ,\n                       color = class)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nFacet Wrapping\nTo split our visualization by a certain categorical variable, we can use facet_wrap(~var)\n\nggplot(data = mpg) + \n  geom_point(mapping = \n               aes(x = displ, \n                   y = hwy), \n             alpha = .5) + \n  facet_wrap(~class)\n\n\n\n\n\n\n\n\nSimilarly, we can split a visualization across 2 variables using facet_grid(var1~var2)\n\nggplot(data = mpg) + \n  geom_point(mapping = \n               aes(x = displ, \n                   y = hwy),\n             alpha = .5) + \n  facet_grid(drv ~ cyl)\n\n\n\n\n\n\n\n\n\n\nGeometric Objects\nUsing the different kinds of geom_*() functions, we can visualize data in multiple ways\nExamples of geom_*() functions:\n\ngeom_bar(): Bar Chart\ngeom_histogram(): Histogram\ngeom_line(): Line Graph\ngeom_boxplot(): Box Plot\ngeom_point(): Scatterplot\ngeom_smooth(): Fitted Line (with error range)\n\nMultiple of each geom_*() can be used in a visualization to represent data differently\n\n\nStatistical Transformations\nThere are many ways that data can be represented / changed in order to better convey the point you are trying to show through a visualization. We may employ a log transformation on data sets with larger values to better visualize smaller (%) changes, for example.\n\nsale_df &lt;- read_csv(\"https://bcdanl.github.io/data/home_sales_nyc.csv\")\n\n\n# Without transformation\nggplot(data=sale_df, aes(x=sale_price), bins = 500) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n# With transformation\nggplot(data=sale_df, aes(x=log(sale_price)), bins = 500) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nWith transformations, large values and skewed data become much more interpretable.\n\n\nCount vs. Proportion\nWith geometric objects that count the number of instances for a value (such as geom_bar() or geom_histogram()), we can also use a proportion of the entire data set to represent the data with after_stat() or stat()\n\nggplot(data = diamonds) + \n  geom_bar(mapping = \n             aes(x = cut))\n\n\n\n\n\n\n\n\n\nggplot(data = diamonds) + \n  geom_bar(mapping = \n             aes(x = cut, \n                 y = after_stat(prop), \n                 group = 1))\n\n\n\n\n\n\n\n\n\n\nPosition Adjustment\nSome geometric objects have the ability to have their ‘positions’ adjusted, meaning that they are able to be further split categorically in multiple ways.\n\n# No Adjustment\nggplot(data = diamonds) + \n  geom_bar(mapping = \n             aes(x = cut, \n                 fill = cut))\n\n\n\n\n\n\n\n\n\n# Position = 'stack'\nggplot(data = diamonds) + \n  geom_bar(mapping = \n             aes(x = cut, \n                 fill = clarity),\n           position = \"stack\")\n\n\n\n\n\n\n\n\n\n# Position = \"dodge\"\nggplot(data = diamonds) + \n  geom_bar(mapping = \n             aes(x = cut, \n                 fill = clarity),\n           position = \"dodge\")\n\n\n\n\n\n\n\n\n\n# Position = 'fill'\nggplot(data = diamonds) + \n  geom_bar(mapping = \n             aes(x = cut, \n                 fill = clarity),\n           position = \"fill\")\n\n\n\n\n\n\n\n\n\n\nggplot Grammar\n\nDATA\nGEOM_FUNCTION\nMAPPINGS\nSTAT\nPOSITION\nCOORDINATE_FUNCTION\nFACET_FUNCTION\nSCALE_FUNCTIONS\nGUIDES\nTHEME\n\n\n\nggplot Themes\nTo assist in presentation and accessibility, there are themes that alter the coloration of a visualization. For example:\n\ntheme_gray()\ntheme_bw()\ntheme_linedraw()\ntheme_light()\ntheme_dark()\ntheme_minimal()\ntheme_classic()\ntheme_void()\ntheme_test()\n\nThe ggthemes package comes with some additional themes:\n\ntheme_economist()\ntheme_wsj()\ntheme_fivethirtyeight()\ntheme_map()\n\nThere are also color palettes that allow for increased accessibility for the colorblind, such as:\n\nscale_color_tableau()\nscale_color_colorblind()\n\n\n\nSaving plots\nWe can use ggsave() to save a ggplot output as a .png or .pdf file\n\nSyntax: ggsave(filename = “—.png”, plot = —)\n\nOptionally, we can alter the dimensions of the figure being output\n\nggsave(‘filename.png’, plot = —, height = —, width = —, units = —)"
  },
  {
    "objectID": "posts/spotify_analysis/spotify_analysis.html",
    "href": "posts/spotify_analysis/spotify_analysis.html",
    "title": "Spotify Favorites Analysis",
    "section": "",
    "text": "Spotify Favorites Analysis\n\nimport pandas as pd\n\nThe following data frame includes spotify user data from the 2018 Spotify Million Dataset Challenge.\n\nspotify = pd.read_csv('https://bcdanl.github.io/data/spotify_all.csv')\n\nOut of all these brilliant artists, I’d like to highlight and analyze some of my favorites:\n\nSaint Motel\nTame Impala\nCastlecomer\nCRX\nTwo Door Cinema Club\n\nFirst, let’s find which songs from each of these artists are in the larger data frame and how many times each song appears:\n\nartist_favorites = ['Saint Motel', 'Tame Impala', 'Castlecomer', 'CRX', 'Two Door Cinema Club']\nspotify_favorites = spotify[spotify['artist_name'].isin(artist_favorites)]\n\n# Song names for each artist\nsong_names_fav = spotify_favorites.drop_duplicates(subset='track_name', keep='first')[['artist_name', 'track_name']].sort_values('artist_name')\nsong_names_fav\n\n\n  \n    \n\n\n\n\n\n\nartist_name\ntrack_name\n\n\n\n\n101794\nCRX\nSlow Down\n\n\n129597\nCastlecomer\nFire Alarm\n\n\n21124\nSaint Motel\nCold Cold Man\n\n\n132905\nSaint Motel\nAce In The Hole - Live from Spotify San Francisco\n\n\n1235\nSaint Motel\nBorn Again\n\n\n...\n...\n...\n\n\n23358\nTwo Door Cinema Club\nYou're Not Stubborn\n\n\n12902\nTwo Door Cinema Club\nWhat You Know - Live\n\n\n16457\nTwo Door Cinema Club\nUndercover Martyn\n\n\n68025\nTwo Door Cinema Club\nEat That Up, Its Good For You\n\n\n195075\nTwo Door Cinema Club\nSpring\n\n\n\n\n77 rows × 2 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n# Number of songs each artist has in the larger spotify DataFrame\nsongs_count_fav = spotify_favorites.drop_duplicates(subset='track_name', keep='first').value_counts('artist_name').sort_values()\nsongs_count_fav\n\n\n\n\n\n\n\n\ncount\n\n\nartist_name\n\n\n\n\n\nCRX\n1\n\n\nCastlecomer\n1\n\n\nSaint Motel\n11\n\n\nTwo Door Cinema Club\n24\n\n\nTame Impala\n40\n\n\n\n\ndtype: int64\n\n\n\n# Times each individual track was listed\nsongs_listed_fav = spotify_favorites.value_counts(['artist_name', 'track_name']).sort_index()\nsongs_listed_fav\n\n\n\n\n\n\n\n\n\ncount\n\n\nartist_name\ntrack_name\n\n\n\n\n\nCRX\nSlow Down\n1\n\n\nCastlecomer\nFire Alarm\n1\n\n\nSaint Motel\nAce In The Hole - Live from Spotify San Francisco\n1\n\n\nBorn Again\n2\n\n\nCold Cold Man\n14\n\n\n...\n...\n...\n\n\nTwo Door Cinema Club\nThis Is The Life\n1\n\n\nUndercover Martyn\n10\n\n\nWhat You Know\n39\n\n\nWhat You Know - Live\n1\n\n\nYou're Not Stubborn\n2\n\n\n\n\n77 rows × 1 columns\ndtype: int64\n\n\nBased on the data, let’s see what the highest and lowest amounts for listed songs were\n\nsongs_listed_fav.nlargest(5, keep='all')\n\n\n\n\n\n\n\n\n\ncount\n\n\nartist_name\ntrack_name\n\n\n\n\n\nTwo Door Cinema Club\nWhat You Know\n39\n\n\nTame Impala\nThe Less I Know The Better\n30\n\n\nFeels Like We Only Go Backwards\n20\n\n\nSaint Motel\nMy Type\n19\n\n\nTwo Door Cinema Club\nSomething Good Can Work\n19\n\n\n\n\ndtype: int64\n\n\n\nsongs_listed_fav.nsmallest(5, keep='all')\n\n\n\n\n\n\n\n\n\ncount\n\n\nartist_name\ntrack_name\n\n\n\n\n\nCRX\nSlow Down\n1\n\n\nCastlecomer\nFire Alarm\n1\n\n\nSaint Motel\nAce In The Hole - Live from Spotify San Francisco\n1\n\n\nDaydream / Wetdream / Nightmare\n1\n\n\nLocal Long Distance Relationship (LA2NY)\n1\n\n\nSomething About Us - Recorded at Spotify Studios NYC\n1\n\n\nSweet Talk\n1\n\n\nYou Can Be You\n1\n\n\nTame Impala\n'Cause I'm A Man - HAIM Remix\n1\n\n\nDesire Be Desire Go\n1\n\n\nExpectation\n1\n\n\nI Don't Really Mind\n1\n\n\nIt Is Not Meant To Be\n1\n\n\nJeremy's Storm\n1\n\n\nKeep On Lying\n1\n\n\nLove/Paranoia\n1\n\n\nMind Mischief - Ducktails Remix\n1\n\n\nReality In Motion\n1\n\n\nRemember Me\n1\n\n\nRunway Houses City Clouds\n1\n\n\nSun's Coming Up\n1\n\n\nSundown Syndrome\n1\n\n\nWander\n1\n\n\nWhy Won't You Make Up Your Mind?\n1\n\n\nTwo Door Cinema Club\nCigarettes In The Theatre\n1\n\n\nGameshow\n1\n\n\nLavender\n1\n\n\nPyramid\n1\n\n\nSleep Alone\n1\n\n\nSomething Good Can Work - RAC Remix\n1\n\n\nSomething Good Can Work - The Twelves remix\n1\n\n\nSpring\n1\n\n\nThis Is The Life\n1\n\n\nWhat You Know - Live\n1\n\n\n\n\ndtype: int64\n\n\nIt seems like there are many instances where tracks are listed only once, which is a shame, but there are plenty of more popular tracks across these artists.\nOf these, it seems like ‘Two Door Cinema Club’ and ‘Tame Impala’ are the two most popular artists of the bunch.\nGoing back to the original ‘spotify_favorites’ DataFrame, we can look at the longest song length as well:\n\nspotify_favorites['duration_min'] = ((spotify_favorites['duration_ms'] / 1000) / 60)\nspotify_favorites.sort_values('duration_min', ascending=False)\n\n\n  \n    \n\n\n\n\n\n\npid\nplaylist_name\npos\nartist_name\ntrack_name\nduration_ms\nalbum_name\nduration_min\n\n\n\n\n64923\n969\nMarshall\n33\nTame Impala\nLet It Happen - Soulwax Remix\n556924\nLet It Happen\n9.282067\n\n\n142147\n999121\n.::March::.\n36\nTame Impala\nLet It Happen - Soulwax Remix\n556924\nLet It Happen\n9.282067\n\n\n165421\n999491\nPlay this at my funeral\n25\nTame Impala\nLet It Happen\n467585\nCurrents\n7.793083\n\n\n19178\n303\nTame Impala\n25\nTame Impala\nLet It Happen\n467585\nCurrents\n7.793083\n\n\n85204\n1276\nFIREFLY 2016\n27\nTame Impala\nLet It Happen\n467585\nCurrents\n7.793083\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n19184\n303\nTame Impala\n31\nTame Impala\nDisciples\n108546\nCurrents\n1.809100\n\n\n171295\n999586\nFall 2017\n1\nTame Impala\nDisciples\n108546\nCurrents\n1.809100\n\n\n101795\n1521\nyoga\n17\nTame Impala\nDisciples\n108546\nCurrents\n1.809100\n\n\n57271\n849\nchill\n63\nTame Impala\nNangs\n107533\nCurrents\n1.792217\n\n\n19179\n303\nTame Impala\n26\nTame Impala\nNangs\n107533\nCurrents\n1.792217\n\n\n\n\n343 rows × 8 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\nInterestingly, both the top 5 and bottom 5 song durations came from ‘Tame Impala’ (most of which from the same album as well), ranging from 9.28 minutes to 1.79 minutes."
  },
  {
    "objectID": "posts/ice_cream/ice_cream_blog.html",
    "href": "posts/ice_cream/ice_cream_blog.html",
    "title": "Ice Cream Blog",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggthemes)\nlibrary(scales)"
  },
  {
    "objectID": "posts/ice_cream/ice_cream_blog.html#descriptive-statistics",
    "href": "posts/ice_cream/ice_cream_blog.html#descriptive-statistics",
    "title": "Ice Cream Blog",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nLet’s take a look at the ice_cream Data Frame, which details Ben & Jerry’s ice cream transactions across various regions and households:\n\nice_cream &lt;- read_csv('https://bcdanl.github.io/data/ben-and-jerry-cleaned.csv')\n\nSome descriptive statistics for the averages of Ice Cream Price, Coupon Discount, and Household Income are shown below for each of the available regions\n\nice_cream |&gt; filter(couponper1 &gt; 0) |&gt; group_by(region) |&gt; \n  summarise(mean_price = mean(priceper1, na.rm=T),\n            mean_coup = mean(couponper1, na.rm=T),\n            mean_inc = mean(household_income, na.rm=T))\n\n# A tibble: 4 × 4\n  region  mean_price mean_coup mean_inc\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 Central       3.44      1.39  123565.\n2 East          3.44      1.12  119340.\n3 South         3.36      1.22  130505.\n4 West          3.29      1.03  125735."
  },
  {
    "objectID": "posts/ice_cream/ice_cream_blog.html#household-size-and-ice-cream-purchases",
    "href": "posts/ice_cream/ice_cream_blog.html#household-size-and-ice-cream-purchases",
    "title": "Ice Cream Blog",
    "section": "Household Size and Ice Cream Purchases",
    "text": "Household Size and Ice Cream Purchases\nAlong with this, we’ll look at a count of the prevalent household sizes in each region:\n\nice_cream_n &lt;- ice_cream |&gt; group_by(region, household_size) |&gt; count(household_size) |&gt; arrange(-n)\nice_cream_n\n\n# A tibble: 36 × 3\n# Groups:   region, household_size [36]\n   region  household_size     n\n   &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt;\n 1 South                2  2870\n 2 Central              2  1993\n 3 West                 2  1812\n 4 East                 2  1797\n 5 West                 1  1682\n 6 South                1  1604\n 7 West                 3  1063\n 8 Central              1  1016\n 9 South                3  1005\n10 East                 1   971\n# ℹ 26 more rows\n\n\n\nggplot(ice_cream, aes(y = household_size,\n                      fill = region)) +\n  geom_bar() +\n  scale_y_continuous(breaks = c(0,2,4,6,8)) +\n  facet_wrap(~region) +\n  labs(x = \"# of Ice Cream Bought\",\n       y = \"Household Size\",\n       fill = \"Region\",\n       title = \"Ice Cream Purchases by Regional Household Size\") +\n  scale_fill_tableau() +\n  theme_minimal() +\n  theme(strip.background = element_rect(fill = 'gray90',\n                                        color = 'transparent'))\n\n\n\n\n\n\n\n\nFrom this, it appears that there is a consistent relationship where 2 person households purchase Ben & Jerry’s the most, followed by 1, 3, 4, and 5 person households across the 4 regions. The South has the most purchases overall, and Central has the least."
  },
  {
    "objectID": "posts/ice_cream/ice_cream_blog.html#marriage-and-ice-cream-purchases",
    "href": "posts/ice_cream/ice_cream_blog.html#marriage-and-ice-cream-purchases",
    "title": "Ice Cream Blog",
    "section": "Marriage and Ice Cream Purchases",
    "text": "Marriage and Ice Cream Purchases\nSimilarly, we can visualize how purchases are influenced by the income and marriage status of each household:\n\nice_cream2 &lt;- ice_cream\n\nice_cream2$household_income &lt;- as.factor(ice_cream2$household_income)\n\nggplot(ice_cream2, aes(y = household_income,\n                      fill = married)) +\n  geom_bar() +\n  labs(x = \"# of Ice Cream Bought\",\n       y = \"Household Income Bracket (in dollars)\",\n       title = \"Ice Cream Purchases by Income Bracket\",\n       fill = \"Married\") +\n  guides(fill = guide_legend(reverse = T)) +\n  scale_fill_tableau() +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nThis shows that many of Ben & Jerry’s sales come from households between an income range of $70,000-$140,000 (because the 130,000 income bracket covers from 130,000 to 140,000), and that the ratio of married to unmarried households is much higher as incomes become lower.\nVisualizing this with a “filled” bar chart, we can more easily notice this relationship, where there is a high percentage of married, low income households:\n\ninc_married_pct &lt;- ice_cream |&gt; group_by(household_income, married) |&gt; summarise(n = n()) |&gt; mutate(pct = n / sum(n))\n\nggplot(inc_married_pct, aes(x = pct,\n                        y = reorder(household_income, pct),\n                        fill = married)) +\n  geom_col() +\n  scale_x_continuous(labels = scales::percent) +\n  scale_fill_tableau() +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  labs(x = NULL,\n       y = \"Household Income Bracket (in dollars)\",\n       fill = \"Married\",\n       title = \"Married Households Across Income Brackets\") +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "posts/dog_analysis/dog_breed_blog_post.html",
    "href": "posts/dog_analysis/dog_breed_blog_post.html",
    "title": "Dog Breed Blog",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidytext)\nlibrary(ggthemes)\nlibrary(reactable)"
  },
  {
    "objectID": "posts/dog_analysis/dog_breed_blog_post.html#required-packages",
    "href": "posts/dog_analysis/dog_breed_blog_post.html#required-packages",
    "title": "Dog Breed Blog",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidytext)\nlibrary(ggthemes)\nlibrary(reactable)"
  },
  {
    "objectID": "posts/dog_analysis/dog_breed_blog_post.html#data-transformation",
    "href": "posts/dog_analysis/dog_breed_blog_post.html#data-transformation",
    "title": "Dog Breed Blog",
    "section": "Data Transformation",
    "text": "Data Transformation\n\nnyc_dog_license &lt;- read_csv('https://bcdanl.github.io/data/nyc_dog_license.csv')\nnyc_zips_coord &lt;- read_csv('https://bcdanl.github.io/data/nyc_zips_coord.csv')\nnyc_zips_df &lt;- read_csv('https://bcdanl.github.io/data/nyc_zips_df.csv')\n\n\ntop10_breeds &lt;- nyc_dog_license |&gt; count(breed_rc) |&gt; arrange(-n) |&gt; head(10)\ntop10_breeds$breed_rc\n\n [1] \"Yorkshire Terrier\"        \"Labrador (or Crossbreed)\"\n [3] \"Shih Tzu\"                 \"Pit Bull (or Mix)\"       \n [5] \"Chihuahua\"                \"Maltese\"                 \n [7] \"Pomeranian\"               \"Havanese\"                \n [9] \"Shih Tzu Crossbreed\"      \"Beagle\"                  \n\n\n\ndog_df &lt;- nyc_dog_license |&gt; filter(!is.na(borough), breed_rc %in% top10_breeds$breed_rc) |&gt; \n  count(borough, breed_rc) |&gt; group_by(borough) |&gt; arrange(-n)\n\ndog_df$breed_rc &lt;- factor(dog_df$breed_rc, levels = top10_breeds$breed_rc)\n\nreactable(dog_df, columns = list(borough = colDef(name = \"Borough\"),\n                                 breed_rc = colDef(name = \"Breed\"),\n                                 n = colDef(name = \"Count\")))\n\n\n\n\n\n\nggplot(dog_df, aes(x = n, y = reorder_within(breed_rc, n, borough),\n                   fill = breed_rc)) +\n  geom_col(width = 1, color = \"gray40\", linewidth = 0.2) +\n  facet_wrap(~borough, scales = \"free_y\", ncol = 1) +\n  scale_y_reordered() +\n  scale_fill_tableau() +\n  labs(x = \"Count\",\n       y = NULL,\n       fill = \"Breeds\",\n       title = \"Dog Breeds Across NYC Boroughs\") +\n  guides(fill = guide_legend(keyheight = 2.3)) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, size = 18, face = \"bold\"),\n        axis.text = element_text(size = 10),\n        legend.text = element_text(size = 10),\n        strip.text = element_text(size = 10, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nbreed_zips &lt;- nyc_dog_license |&gt; group_by(zip_code) |&gt; count(breed_rc) |&gt; \n  mutate(prop_breed = round(n/sum(n)*100, 2)) |&gt; mutate(is_max = ifelse(prop_breed == max(prop_breed), \"Yes\", \"No\"))\nbreed_zips_max &lt;- breed_zips |&gt; filter(is_max == \"Yes\") |&gt; filter(!duplicated(zip_code))\n\nbreed_join_1 &lt;- left_join(breed_zips_max, nyc_zips_df)\nbreed_join_full &lt;- left_join(breed_join_1, nyc_zips_coord)\nbreed_join_full &lt;- breed_join_full |&gt; filter(!is.na(objectid))\n\nreactable(breed_zips, columns = list(zip_code = colDef(name = \"Zip Code\"),\n                                breed_rc = colDef(name = \"Breed\"),\n                                n = colDef(name = \"Count\"),\n                                prop_breed = colDef(name = \"% Breed\"),\n                                is_max = colDef(name = \"Most Popular?\")))\n\n\n\n\n\n\nggplot(breed_join_full, aes(x = X, y = Y,\n                            fill = breed_rc,\n                            group = objectid)) +\n  geom_polygon(color = \"gray30\", linewidth = 0.1) +\n  coord_map(projection = \"albers\", lat0 = 39, lat1 = 45) +\n  scale_fill_tableau() +\n  labs(title = \"NYC: Most Popular Dog Breeds by Zip Code\",\n       fill = \"Breed\") +\n  guides(fill = guide_legend(keyheight = 1.25)) +\n  theme_void() +\n  theme(plot.title = element_text(size = 15,\n                                  face = \"bold\"),\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8))"
  },
  {
    "objectID": "posts/dog_analysis/dog_breed_blog_post.html#data-frames-used",
    "href": "posts/dog_analysis/dog_breed_blog_post.html#data-frames-used",
    "title": "Dog Breed Blog",
    "section": "Data Frames Used",
    "text": "Data Frames Used\n\nnyc_dog_license &lt;- read_csv('https://bcdanl.github.io/data/nyc_dog_license.csv')\nnyc_zips_coord &lt;- read_csv('https://bcdanl.github.io/data/nyc_zips_coord.csv')\nnyc_zips_df &lt;- read_csv('https://bcdanl.github.io/data/nyc_zips_df.csv')"
  },
  {
    "objectID": "posts/dog_analysis/dog_breed_blog_post.html#dog-breeds-across-nyc-boroughs",
    "href": "posts/dog_analysis/dog_breed_blog_post.html#dog-breeds-across-nyc-boroughs",
    "title": "Dog Breed Blog",
    "section": "Dog Breeds Across NYC Boroughs",
    "text": "Dog Breeds Across NYC Boroughs\n\ntop10_breeds &lt;- nyc_dog_license |&gt; count(breed_rc) |&gt; arrange(-n) |&gt; head(10)\ntop10_breeds$breed_rc\n\n [1] \"Yorkshire Terrier\"        \"Labrador (or Crossbreed)\"\n [3] \"Shih Tzu\"                 \"Pit Bull (or Mix)\"       \n [5] \"Chihuahua\"                \"Maltese\"                 \n [7] \"Pomeranian\"               \"Havanese\"                \n [9] \"Shih Tzu Crossbreed\"      \"Beagle\"                  \n\n\n\ndog_df &lt;- nyc_dog_license |&gt; filter(!is.na(borough), breed_rc %in% top10_breeds$breed_rc) |&gt; \n  count(borough, breed_rc) |&gt; group_by(borough) |&gt; arrange(-n)\n\ndog_df$breed_rc &lt;- factor(dog_df$breed_rc, levels = top10_breeds$breed_rc)\n\nreactable(dog_df, columns = list(borough = colDef(name = \"Borough\"),\n                                 breed_rc = colDef(name = \"Breed\"),\n                                 n = colDef(name = \"Count\")))\n\n\n\n\n\n\nggplot(dog_df, aes(x = n, y = reorder_within(breed_rc, n, borough),\n                   fill = breed_rc)) +\n  geom_col(width = 1, color = \"gray40\", linewidth = 0.2) +\n  facet_wrap(~borough, scales = \"free_y\", ncol = 1) +\n  scale_y_reordered() +\n  scale_fill_tableau() +\n  labs(x = \"Count\",\n       y = NULL,\n       fill = \"Breeds\",\n       title = \"Dog Breeds Across NYC Boroughs\") +\n  guides(fill = guide_legend(keyheight = 2.3)) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, size = 18, face = \"bold\"),\n        axis.text = element_text(size = 10),\n        legend.text = element_text(size = 10),\n        strip.text = element_text(size = 10, face = \"bold\"))"
  },
  {
    "objectID": "posts/dog_analysis/dog_breed_blog_post.html#popular-dog-breeds-across-zip-codes",
    "href": "posts/dog_analysis/dog_breed_blog_post.html#popular-dog-breeds-across-zip-codes",
    "title": "Dog Breed Blog",
    "section": "Popular Dog Breeds Across Zip Codes",
    "text": "Popular Dog Breeds Across Zip Codes\n\nbreed_zips &lt;- nyc_dog_license |&gt; group_by(zip_code) |&gt; count(breed_rc) |&gt; \n  mutate(prop_breed = round(n/sum(n)*100, 2)) |&gt; mutate(is_max = ifelse(prop_breed == max(prop_breed), \"Yes\", \"No\"))\nbreed_zips_max &lt;- breed_zips |&gt; filter(is_max == \"Yes\") |&gt; filter(!duplicated(zip_code))\n\nbreed_join_1 &lt;- left_join(breed_zips_max, nyc_zips_df)\nbreed_join_full &lt;- left_join(breed_join_1, nyc_zips_coord)\nbreed_join_full &lt;- breed_join_full |&gt; filter(!is.na(objectid))\n\nreactable(breed_zips, columns = list(zip_code = colDef(name = \"Zip Code\"),\n                                breed_rc = colDef(name = \"Breed\"),\n                                n = colDef(name = \"Count\"),\n                                prop_breed = colDef(name = \"% Breed\"),\n                                is_max = colDef(name = \"Most Popular?\")))\n\n\n\n\n\n\nggplot(breed_join_full, aes(x = X, y = Y,\n                            fill = breed_rc,\n                            group = objectid)) +\n  geom_polygon(color = \"gray30\", linewidth = 0.1) +\n  coord_map(projection = \"albers\", lat0 = 39, lat1 = 45) +\n  scale_fill_tableau() +\n  labs(title = \"NYC: Most Popular Dog Breeds by Zip Code\",\n       fill = \"Breed\") +\n  guides(fill = guide_legend(keyheight = 1.25)) +\n  theme_void() +\n  theme(plot.title = element_text(size = 15,\n                                  face = \"bold\"),\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8))"
  },
  {
    "objectID": "danl_210_final_project_hayden_mikula.html",
    "href": "danl_210_final_project_hayden_mikula.html",
    "title": "DANL 210 - Unifying ESG Metrics with Financial Analysis",
    "section": "",
    "text": "In 2016, Morningstar released the first iteration of the Environmental, Social, and Governance (ESG) scores using data collected by Sustainalytic’s ESG research efforts, with the intention to make insider information surrounding companies and investment risk much more accessible to the public. Today these ratings are largely standardized, being featured alongside company’s financial information on prominent market data websites such as Yahoo Finance.\nFor these websites, the ESG ratings are indicators of an institution’s risk relating to various sustainability metrics and general level of public controversy, and serve as general influences to consumer investment. In a survey conducted by Morningstar in September of 2024, 67% of asset owners believe that the ESG rating scheme has become more integral to their investment decisions.\nWith these ratings being presented alongside company-wise financial data such as historical stock price and income statements, the question arises: Just how effective is the ESG rating in predicting public investment decisions / outlooks?\nExploratory Questions:\n\nHow concerned are companies with reducing their ESG risk?\nWhich industries typically have the highest ESG risk assessments?\nDo ESG ratings affect stock prices?\n\n\nLibrary & File Setup\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nfrom google.colab import drive\n\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\n\nurl_2024 = \"https://bcdanl.github.io/data/esg_proj_2024_data.csv\"\nesg_2024 = pd.read_csv(url_2024)\nesg_2024 = esg_2024.rename({'Total_ESG':'total_esg'}, axis=1)\n\nesg_2025 = pd.read_csv('/content/danl_210_mikula_hayden_esg.csv')\nstocks = pd.read_csv('/content/danl_210_mikula_hayden_stock.csv')\n\n\n\nData Sets\nThe data that this analysis uses is comprised of:\n\nThe individual Total ESG, Environmental, Social, Governance, and Controversy ratings for 625 companies in 2024, along with the stock price financial data for these 625 companies from January 1st, 2024 - March 31st, 2025\nThe individual Total ESG, Environmental, Social, Governance, and Controversy ratings for 3135 companies in 2025\n\nAll data was scraped from each company’s Historical Data and Sustainability sections on Yahoo Finance respectively\n\n\n\nESG Data\n\nesg_2024\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\ntotal_esg\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2024\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n40365434818\n1999.0\n13.6\n1.1\n6.4\n6.1\n2.0\n\n\n1\n2024\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n6622135551\n2016.0\n24.0\n13.8\n5.9\n4.3\n3.0\n\n\n2\n2024\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n9088024606\nNaN\n26.4\n9.9\n11.6\n4.8\n2.0\n\n\n3\n2024\nAAP\nAdvance Auto Parts Inc.\nConsumer Discretionary\nAuto & Home Supply Stores\nUnited States\n4474665296\nNaN\n11.5\n0.1\n8.3\n3.1\n2.0\n\n\n4\n2024\nAAPL\nApple Inc. Common Stock\nTechnology\nComputer Manufacturing\nUnited States\n2614310000000\n1980.0\n17.2\n0.5\n7.4\n9.4\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n620\n2024\nXYL\nXylem Inc. Common Stock New\nIndustrials\nFluid Controls\nUnited States\n32010402681\n2011.0\n18.1\n4.3\n8.7\n5.2\n1.0\n\n\n621\n2024\nYUM\nYum! Brands Inc.\nConsumer Discretionary\nRestaurants\nUnited States\n39885044416\nNaN\n20.1\n4.5\n11.4\n4.1\n2.0\n\n\n622\n2024\nZ\nZillow Group Inc. Class C Capital Stock\nConsumer Discretionary\nBusiness Services\nUnited States\n10195469129\nNaN\n22.2\n1.2\n11.5\n9.5\n2.0\n\n\n623\n2024\nZBH\nZimmer Biomet Holdings Inc. Common Stock\nHealth Care\nIndustrial Specialties\nUnited States\n24476778026\nNaN\n26.0\n3.6\n14.5\n7.9\n2.0\n\n\n624\n2024\nZTS\nZoetis Inc. Class A Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n72535308358\n2013.0\n18.8\n3.2\n6.8\n8.7\n2.0\n\n\n\n\n625 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nesg_2025\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\ntotal_esg\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2025\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n3.391867e+10\n1999.0\n10.1\n1.1\n5.0\n3.9\n1.0\n\n\n1\n2025\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n8.279121e+09\n2016.0\n25.1\n14.7\n8.0\n2.4\n3.0\n\n\n2\n2025\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n7.325392e+09\nNaN\n23.8\n9.6\n11.3\n2.9\n2.0\n\n\n3\n2025\nAAMI\nAcadian Asset Management Inc. Common Stock\nFinance\nInvestment Managers\nUnited Kingdom\n9.987823e+08\n2014.0\n31.3\nNaN\nNaN\nNaN\nNaN\n\n\n4\n2025\nAAON\nAAON Inc. Common Stock\nIndustrials\nIndustrial Machinery/Components\nUnited States\n6.547366e+09\nNaN\n21.5\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3130\n2025\nZUMZ\nZumiez Inc. Common Stock\nConsumer Discretionary\nClothing/Shoe/Accessory Stores\nUnited States\n2.929444e+08\n2005.0\n15.1\nNaN\nNaN\nNaN\n1.0\n\n\n3131\n2025\nZVIA\nZevia PBC Class A Common Stock\nConsumer Staples\nBeverages (Production/Distribution)\nUnited States\n1.565735e+08\n2021.0\n32.9\nNaN\nNaN\nNaN\nNaN\n\n\n3132\n2025\nZVRA\nZevra Therapeutics Inc. Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n4.307623e+08\nNaN\n34.6\nNaN\nNaN\nNaN\nNaN\n\n\n3133\n2025\nZWS\nZurn Elkay Water Solutions Corporation Common ...\nIndustrials\nIndustrial Machinery/Components\nUnited States\n5.741099e+09\n2012.0\n14.3\n8.3\n2.8\n3.3\nNaN\n\n\n3134\n2025\nZYME\nZymeworks Inc. Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n8.704068e+08\nNaN\n29.0\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n3135 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n\nStock Data\n\nstocks\n\n\n  \n    \n\n\n\n\n\n\nSymbol\nName\nDate\nOpen\nHigh\nLow\nClose\nAdj. Close\nVolume\nDividend\n\n\n\n\n0\nA\nAgilent Technologies Inc. Common Stock\n2025-03-28\n119.21\n119.66\n116.36\n116.69\n116.44\n1772900.0\nNaN\n\n\n1\nA\nAgilent Technologies Inc. Common Stock\n2025-03-27\n120.00\n120.33\n118.73\n118.97\n118.72\n2075700.0\nNaN\n\n\n2\nA\nAgilent Technologies Inc. Common Stock\n2025-03-26\n120.72\n121.14\n119.05\n119.90\n119.65\n2652900.0\nNaN\n\n\n3\nA\nAgilent Technologies Inc. Common Stock\n2025-03-25\n122.60\n123.04\n119.76\n120.51\n120.25\n1605900.0\nNaN\n\n\n4\nA\nAgilent Technologies Inc. Common Stock\n2025-03-24\n121.88\n124.43\n120.89\n121.97\n121.71\n1557400.0\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n194370\nZTS\nZoetis Inc. Class A Common Stock\n2024-01-08\n194.53\n196.28\n192.67\n196.15\n192.99\n1610600.0\nNaN\n\n\n194371\nZTS\nZoetis Inc. Class A Common Stock\n2024-01-05\n193.07\n195.94\n193.07\n194.85\n191.71\n1088200.0\nNaN\n\n\n194372\nZTS\nZoetis Inc. Class A Common Stock\n2024-01-04\n192.85\n194.93\n192.01\n194.04\n190.91\n1851900.0\nNaN\n\n\n194373\nZTS\nZoetis Inc. Class A Common Stock\n2024-01-03\n195.92\n195.95\n192.80\n192.93\n189.82\n1493000.0\nNaN\n\n\n194374\nZTS\nZoetis Inc. Class A Common Stock\n2024-01-02\n195.79\n197.95\n195.05\n196.57\n193.40\n1642300.0\nNaN\n\n\n\n\n194375 rows × 10 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n\n\nData Exploration\n\nHow concerned are companies with reducing their ESG risk?\nTo begin, let’s compare the distribution of Total ESG ratings from the common companies between the two available ESG-related data frames, along with being split by Year:\n\n(\n    sns.histplot(data=esg_2024, x = 'total_esg', kde = True, bins = 25)\n    .set(xlabel=\"Total ESG\", ylabel=\"Count\", title=\"Distribution of Company-Wise Total ESG (2024)\")\n)\n\nfor l in [esg_2024['total_esg'].quantile(0.25), esg_2024['total_esg'].mean() , esg_2024['total_esg'].quantile(0.75)]:\n  plt.axvline(x = l, alpha = 0.75, color = 'orange')\n\nplt.xticks(ticks=[0,5,10,15,20,25,30,35,40,45,50,55])\n\nplt.show()\n\n\n\n\n\n\n\n\n\nesg_common_2025 = esg_2025[esg_2025['Symbol'].isin(esg_2024['Symbol'])].reset_index()\n\n\n(\n    sns.histplot(data=esg_common_2025, x = 'total_esg', kde = True, bins = 25)\n    .set(xlabel=\"Total ESG\", ylabel=\"Count\", title=\"Distribution of Company-Wise Total ESG (2025)\")\n)\n\nfor l in [esg_common_2025['total_esg'].quantile(0.25), esg_common_2025['total_esg'].mean() , esg_common_2025['total_esg'].quantile(0.75)]:\n  plt.axvline(x = l, alpha = 0.75, color = 'orange')\n\nplt.xticks(ticks=[0,5,10,15,20,25,30,35,40,45,50,55])\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.histplot(data = esg_2024[~esg_2024['total_esg'].isna()], x = 'total_esg', kde=True, label = '2024', bins = 25),\nsns.histplot(data = esg_common_2025[~esg_common_2025['total_esg'].isna()], x = 'total_esg', kde=True, label = '2025', bins = 25)\n\nplt.title(\"Distribution of Company-Wise Total ESG\")\nplt.xlabel(\"Total ESG Rating\")\nplt.ylabel(\"Count\")\n\nplt.xticks(ticks=[0,5,10,15,20,25,30,35,40,45,50,55])\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\nFrom this, it can be observed that there hasn’t been a total ESG shift in favor of a higher/lower average. However, from 2024 to 2025 the distribution of ESG ratings has normalized slightly, dispersing the higher concentration of values surrounding the mean in 2024 more towards the ends of the distribution that reflects movement towards a lower risk overall, though it isn’t significant.\nTo get a better idea of what caused this dispersion, let’s look at the distributions of the individual parts that make up the Total ESG rating:\n\nsns.histplot(data = esg_2024[~esg_2024['Environmental'].isna()], x = 'Environmental', kde=True, label = '2024', bins = 30),\nsns.histplot(data = esg_common_2025[~esg_common_2025['Environmental'].isna()], x = 'Environmental', kde=True, label = '2025', bins = 30)\n\nplt.title(\"Environmental Risk Distribution 2024-2025\")\nplt.xlabel(\"'Environmental' Score\")\nplt.ylabel(\"Count\")\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.histplot(data = esg_2024[~esg_2024['Social'].isna()], x = 'Social', kde=True, label = '2024', bins = 30),\nsns.histplot(data = esg_common_2025[~esg_common_2025['Social'].isna()], x = 'Social', kde=True, label = '2025', bins = 30)\n\nplt.title(\"Social Risk Distribution 2024-2025\")\nplt.xlabel(\"'Social' Score\")\nplt.ylabel(\"Count\")\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.histplot(data = esg_2024[~esg_2024['Governance'].isna()], x = 'Governance', kde=True, label = '2024', bins = 30),\nsns.histplot(data = esg_common_2025[~esg_common_2025['Governance'].isna()], x = 'Governance', kde=True, label = '2025', bins = 30)\n\nplt.title(\"Governance Risk Distribution 2024-2025\")\nplt.xlabel(\"'Governance' Score\")\nplt.ylabel(\"Count\")\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\nGovernance is the most adjusted attribute, with there being a real shift in the distribution itself by ~1.25 points in favor of a lower risk, rather than the values being merely redistributed. This tells us that companies have generally been making efforts to refine/redefine their structures, public transparency, and/or stockholder rights.\nThis is likely due to the 2024 amendment to the ESG by Morningstar to incorporate issues relating to material usage (such as water or raw materials) as a contributor to a lacking corporate governance structure, urging companies to find ways to limit material waste in addition to its existing effect in reducing Environmental risk as well.\nLooking at the Environmental distribution, though, we see that this combined effect isn’t received in the same way, with the amount of companies within the low/medium ranks increasing rather than the average decreasing in the same way as Governance did.\nOne explanation for this could be that there was a reallocation of weights for waste management between the two ratings when the 2024 update occurred, causing the Environmental rating to increase while not being a drastic change as a result of waste management already being a factor, albeit possibly weighted less heavily. For Governance, the waste management parameter was a new addition, so the change would have ended up being more fundamental.\n\n\nWhich Sectors / Industries Typically have the Highest ESG Ratings?\n\n# which industries typically have the highest ESG ratings?\n\nmean_esg_2025 = (\n    esg_2025\n    .groupby(['Sector', 'Industry'])\n    .agg(esg_mean = ('total_esg', 'mean'),\n         esg_std = ('total_esg', 'std'))\n    .dropna()\n    .reset_index()\n)\n\nmean_esg_2025.sort_values('esg_mean', ascending=False)\n\n\n  \n    \n\n\n\n\n\n\nSector\nIndustry\nesg_mean\nesg_std\n\n\n\n\n65\nEnergy\nCoal Mining\n51.025000\n8.421698\n\n\n115\nIndustrials\nFarming/Seeds/Milling\n40.575000\n6.584515\n\n\n1\nBasic Materials\nMetal Mining\n39.956250\n9.653046\n\n\n68\nEnergy\nIntegrated oil Companies\n39.407143\n7.042996\n\n\n70\nEnergy\nOil & Gas Production\n39.156250\n11.617241\n\n\n...\n...\n...\n...\n...\n\n\n12\nConsumer Discretionary\nBooks\n13.550000\n2.050610\n\n\n36\nConsumer Discretionary\nMotor Vehicles\n13.425000\n2.227667\n\n\n38\nConsumer Discretionary\nNewspapers/Magazines\n12.600000\n2.501999\n\n\n46\nConsumer Discretionary\nPublishing\n12.100000\n4.667333\n\n\n39\nConsumer Discretionary\nOffice Equipment/Supplies/Services\n8.775000\n3.031364\n\n\n\n\n166 rows × 4 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\n# Relationship between mean esg and mean esg std deviation; higher mean = higher variance\n\nsns.lmplot(data = mean_esg_2025, x = 'esg_mean', y = 'esg_std')\n\nplt.title(\"Industry Avg. ESG & Std Deviation 2025\")\nplt.xlabel(\"Average Total ESG\")\nplt.ylabel(\"ESG Standard Deviation\")\n\nplt.show()\n\n\n\n\n\n\n\n\nThe prevailing observation here is that there is a strong positive correlation between average ESG and standard deviation. This implies that as ESG ratings become larger, the range between ratings becomes wider in turn, additionally showing that higher ratings among industry peers are less likely to stick as the norm.\nMore industries/companies are coming to the consensus that a lower ESG score is in their best interests, but is this a financial interest or a public relations interest?\n\n\nDo ESG Scores Affect Stock Price?\nTo attempt to answer this question, a possible method could be to plot the relationship between a company’s change in ESG rating and its average stock price. However, this could cause outliers during visualization, beacuse some stocks are valued much higher than others. Instead, I decided to compare the difference in ESG to the average % change of the Adjusted Closing price of a company’s stock, that way the change is more normalized.\nTaking a small random sample from the companies with significant differences in ESG scores, we can start to narrow down the nature of this relationship.\n\ndef rand_sample(n, start, end, seed):\n  random.seed(seed)\n  return random.sample(range(start, end), n)\n\n\n# Example\n\nrand_sample(15, 100, 300, 10)\n  # A sample of 15 numbers from 100-300, with a set seed of '10'\n\n[246, 108, 209, 223, 247, 103, 152, 218, 225, 171, 267, 141, 233, 183, 119]\n\n\n\nesg_diff = pd.DataFrame()\nesg_diff['Symbol'] = esg_2024['Symbol']\nesg_diff['Difference'] = esg_common_2025['total_esg'] - esg_2024['total_esg']\n\nseed = 100\n\nesg_diff_pos = (\n    esg_diff\n    .query(\"Difference &gt; 1 & Difference &lt; 2\")\n    .reset_index(drop=True)\n    .loc[rand_sample(20, 0, esg_diff.query(\"Difference &gt; 1 & Difference &lt; 2\").shape[0]-1, seed)]\n    .reset_index(drop=True)\n)\n\nesg_diff_neg = (\n    esg_diff\n    .query(\"Difference &lt; -1 & Difference &gt; -2\")\n    .reset_index(drop=True)\n    .loc[rand_sample(20, 0, esg_diff.query(\"Difference &lt; -1 & Difference &gt; -2\").shape[0]-1, seed)]\n    .reset_index(drop=True)\n)\n\n\nstocks['adj_pct_change'] = (\n    stocks.groupby('Symbol')['Adj. Close']\n    .transform(lambda x: (x.shift(-1) - x) / x * 100)\n    .shift(1)\n)\n\nstocks[['Name', 'Adj. Close', 'adj_pct_change']]\n\n\n  \n    \n\n\n\n\n\n\nName\nAdj. Close\nadj_pct_change\n\n\n\n\n0\nAgilent Technologies Inc. Common Stock\n116.44\nNaN\n\n\n1\nAgilent Technologies Inc. Common Stock\n118.72\n1.958090\n\n\n2\nAgilent Technologies Inc. Common Stock\n119.65\n0.783356\n\n\n3\nAgilent Technologies Inc. Common Stock\n120.25\n0.501463\n\n\n4\nAgilent Technologies Inc. Common Stock\n121.71\n1.214137\n\n\n...\n...\n...\n...\n\n\n194370\nZoetis Inc. Class A Common Stock\n192.99\n0.108932\n\n\n194371\nZoetis Inc. Class A Common Stock\n191.71\n-0.663247\n\n\n194372\nZoetis Inc. Class A Common Stock\n190.91\n-0.417297\n\n\n194373\nZoetis Inc. Class A Common Stock\n189.82\n-0.570950\n\n\n194374\nZoetis Inc. Class A Common Stock\n193.40\n1.885997\n\n\n\n\n194375 rows × 3 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\nesg_diff_pos['avg_adj_change'] = (\n    stocks[stocks['Symbol'].isin(esg_diff_pos['Symbol'])]\n    .groupby('Symbol')['adj_pct_change']\n    .agg('mean')\n    .reset_index(drop=True)\n)\n\nsns.lmplot(data = esg_diff_pos, x = 'Difference', y = 'avg_adj_change')\n\n\n\n\n\n\n\n\n\nesg_diff_neg['avg_adj_change'] = (\n    stocks[stocks['Symbol'].isin(esg_diff_pos['Symbol'])]\n    .groupby('Symbol')['adj_pct_change']\n    .agg('mean')\n    .reset_index(drop=True)\n)\n\nsns.lmplot(data = esg_diff_neg, x = 'Difference', y = 'avg_adj_change')\n\n\n\n\n\n\n\n\nIt appears that there is a trend with there being a large degree of uncertainty for both visualization’s best fit line, which is indicative of there not being a clear relationship between changes in ESG rating and changes in adjusted closing stock price. The two plots reflect two completely different relationships, one where an increase in ESG correlates to negative changes to stock price, and one where an increase in ESG correlates to a more positive change.\nEven with a combination of these data points, the lack of a definitive relationship is clear, indicated by the near horizontal regression line:\n\nesg_diff_comb = pd.concat([esg_diff_pos, esg_diff_neg]).reset_index(drop=True)\nesg_diff_comb['avg_adj_change'] = (\n    stocks[stocks['Symbol'].isin(esg_diff_comb['Symbol'])]\n    .groupby('Symbol')['adj_pct_change']\n    .agg('mean')\n    .reset_index(drop=True)\n)\n\nsns.lmplot(data = esg_diff_comb, x = 'Difference', y = 'avg_adj_change')\n\n\n\n\n\n\n\n\n\nprint(\"Despite this,\", esg_diff.query(\"Difference &lt; 0\")['Difference'].shape[0] / esg_diff['Difference'].shape[0] * 100\n, \"percent of ESG ratings have lowered between 2024 and 2025.\")\n\nDespite this, 63.2 percent of ESG ratings have lowered between 2024 and 2025.\n\n\n\n\nConclusion\nIn conclusion, although ESG score metrics impact the public outlook of a company, and are not uncommonly considered during consumer investment decisions, they doesn’t seem to retain much usefulness when it comes to a company’s financial gain/loss from stocks.\nA company’s incentive to decrease their ESG rating likely comes from either the desire to be looked upon favorably in comparison to their peers or from the pressures of having a standardized metric of sustainability that they could possibly be held accountable for. Regardless of the lack of a clear relationship, companies are vying for lower ESG ratings as time goes on, improving their corporate structures and endeavoring to make environmentally sustainable decisions, the importance of which cannot be understated.\nWorks Cited:\n\n“About Us.” Morningstar, Inc., morningstar.com/company/about-us. Accessed 14 May 2025.\nKuh, Thomas. “Voice of the Asset Owner Survey 2024 Quantitative Analysis.” Morningstar Indexes, 23 Sept. 2024, indexes.morningstar.com/insights/analysis/blt435a08d683d95490/voice-of-the-asset-owner-survey-2024-quantitative-analysis. Accessed 14 May 2025.\n“Morningstar Sustainalytics Introduces Significant Enhancements to Its ESG Risk Ratings.” Sustainalytics.Com, 12 June 2024, sustainalytics.com/esg-news/news-details/2024/06/12/morningstar-indexes-introduces-morningstar-sustainalytics-introduces-significant-enhancements-to-its-esg-risk-ratings#:~:text=Upgrade%20to%20corporate%20governance%20methodology%20and%20strengthening,since%20industry%2Dleading%20ratings%20were%20introduced%20in%202018.&text=Sustainalytics%20will%20also%20strengthen%20its%20material%20ESG,which%20underpin%20the%20ESG%20risk%20ratings%20methodology.\nYahoo! Finance, Yahoo!, finance.yahoo.com/. Accessed 14 May 2025."
  },
  {
    "objectID": "danl_210_hayden_mikula_stock_esg.html",
    "href": "danl_210_hayden_mikula_stock_esg.html",
    "title": "DANL 210 - Unifying ESG Metrics with Financial Analysis",
    "section": "",
    "text": "In 2016, Morningstar released the first iteration of the Environmental, Social, and Governance (ESG) scores using data collected by Sustainalytic’s ESG research efforts, with the intention to make insider information surrounding companies and investment risk much more accessible to the public. Today these ratings are largely standardized, being featured alongside company’s financial information on prominent market data websites such as Yahoo Finance.\nFor these websites, the ESG ratings are indicators of an institution’s risk relating to various sustainability metrics and general level of public controversy, and serve as general influences to consumer investment. In a survey conducted by Morningstar in September of 2024, 67% of asset owners believe that the ESG rating scheme has become more integral to their investment decisions.\nWith these ratings being presented alongside company-wise financial data such as historical stock price and income statements, the question arises: Just how effective is the ESG rating in predicting public investment decisions / outlooks?\nExploratory Questions:\n\nHow concerned are companies with reducing their ESG risk?\nWhich industries typically have the highest ESG risk assessments?\nDo ESG ratings affect stock prices?\n\n\nLibrary & File Setup\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nfrom google.colab import drive\n\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\n\nurl_2024 = \"https://bcdanl.github.io/data/esg_proj_2024_data.csv\"\nesg_2024 = pd.read_csv(url_2024)\nesg_2024 = esg_2024.rename({'Total_ESG':'total_esg'}, axis=1)\n\nesg_2025 = pd.read_csv('/content/danl_210_mikula_hayden_esg.csv')\nstocks = pd.read_csv('/content/danl_210_mikula_hayden_stock.csv')\n\n\n\nData Sets\nThe data that this analysis uses is comprised of:\n\nThe individual Total ESG, Environmental, Social, Governance, and Controversy ratings for 625 companies in 2024, along with the stock price financial data for these 625 companies from January 1st, 2024 - March 31st, 2025\nThe individual Total ESG, Environmental, Social, Governance, and Controversy ratings for 3135 companies in 2025\n\nAll data was scraped from each company’s Historical Data and Sustainability sections on Yahoo Finance respectively\n\n\n\nESG Data\n\nesg_2024\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\ntotal_esg\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2024\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n40365434818\n1999.0\n13.6\n1.1\n6.4\n6.1\n2.0\n\n\n1\n2024\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n6622135551\n2016.0\n24.0\n13.8\n5.9\n4.3\n3.0\n\n\n2\n2024\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n9088024606\nNaN\n26.4\n9.9\n11.6\n4.8\n2.0\n\n\n3\n2024\nAAP\nAdvance Auto Parts Inc.\nConsumer Discretionary\nAuto & Home Supply Stores\nUnited States\n4474665296\nNaN\n11.5\n0.1\n8.3\n3.1\n2.0\n\n\n4\n2024\nAAPL\nApple Inc. Common Stock\nTechnology\nComputer Manufacturing\nUnited States\n2614310000000\n1980.0\n17.2\n0.5\n7.4\n9.4\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n620\n2024\nXYL\nXylem Inc. Common Stock New\nIndustrials\nFluid Controls\nUnited States\n32010402681\n2011.0\n18.1\n4.3\n8.7\n5.2\n1.0\n\n\n621\n2024\nYUM\nYum! Brands Inc.\nConsumer Discretionary\nRestaurants\nUnited States\n39885044416\nNaN\n20.1\n4.5\n11.4\n4.1\n2.0\n\n\n622\n2024\nZ\nZillow Group Inc. Class C Capital Stock\nConsumer Discretionary\nBusiness Services\nUnited States\n10195469129\nNaN\n22.2\n1.2\n11.5\n9.5\n2.0\n\n\n623\n2024\nZBH\nZimmer Biomet Holdings Inc. Common Stock\nHealth Care\nIndustrial Specialties\nUnited States\n24476778026\nNaN\n26.0\n3.6\n14.5\n7.9\n2.0\n\n\n624\n2024\nZTS\nZoetis Inc. Class A Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n72535308358\n2013.0\n18.8\n3.2\n6.8\n8.7\n2.0\n\n\n\n\n625 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nesg_2025\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\ntotal_esg\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2025\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n3.391867e+10\n1999.0\n10.1\n1.1\n5.0\n3.9\n1.0\n\n\n1\n2025\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n8.279121e+09\n2016.0\n25.1\n14.7\n8.0\n2.4\n3.0\n\n\n2\n2025\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n7.325392e+09\nNaN\n23.8\n9.6\n11.3\n2.9\n2.0\n\n\n3\n2025\nAAMI\nAcadian Asset Management Inc. Common Stock\nFinance\nInvestment Managers\nUnited Kingdom\n9.987823e+08\n2014.0\n31.3\nNaN\nNaN\nNaN\nNaN\n\n\n4\n2025\nAAON\nAAON Inc. Common Stock\nIndustrials\nIndustrial Machinery/Components\nUnited States\n6.547366e+09\nNaN\n21.5\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3130\n2025\nZUMZ\nZumiez Inc. Common Stock\nConsumer Discretionary\nClothing/Shoe/Accessory Stores\nUnited States\n2.929444e+08\n2005.0\n15.1\nNaN\nNaN\nNaN\n1.0\n\n\n3131\n2025\nZVIA\nZevia PBC Class A Common Stock\nConsumer Staples\nBeverages (Production/Distribution)\nUnited States\n1.565735e+08\n2021.0\n32.9\nNaN\nNaN\nNaN\nNaN\n\n\n3132\n2025\nZVRA\nZevra Therapeutics Inc. Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n4.307623e+08\nNaN\n34.6\nNaN\nNaN\nNaN\nNaN\n\n\n3133\n2025\nZWS\nZurn Elkay Water Solutions Corporation Common ...\nIndustrials\nIndustrial Machinery/Components\nUnited States\n5.741099e+09\n2012.0\n14.3\n8.3\n2.8\n3.3\nNaN\n\n\n3134\n2025\nZYME\nZymeworks Inc. Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n8.704068e+08\nNaN\n29.0\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n3135 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n\nStock Data\n\nstocks\n\n\n  \n    \n\n\n\n\n\n\nSymbol\nName\nDate\nOpen\nHigh\nLow\nClose\nAdj. Close\nVolume\nDividend\n\n\n\n\n0\nA\nAgilent Technologies Inc. Common Stock\n2025-03-28\n119.21\n119.66\n116.36\n116.69\n116.44\n1772900.0\nNaN\n\n\n1\nA\nAgilent Technologies Inc. Common Stock\n2025-03-27\n120.00\n120.33\n118.73\n118.97\n118.72\n2075700.0\nNaN\n\n\n2\nA\nAgilent Technologies Inc. Common Stock\n2025-03-26\n120.72\n121.14\n119.05\n119.90\n119.65\n2652900.0\nNaN\n\n\n3\nA\nAgilent Technologies Inc. Common Stock\n2025-03-25\n122.60\n123.04\n119.76\n120.51\n120.25\n1605900.0\nNaN\n\n\n4\nA\nAgilent Technologies Inc. Common Stock\n2025-03-24\n121.88\n124.43\n120.89\n121.97\n121.71\n1557400.0\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n194370\nZTS\nZoetis Inc. Class A Common Stock\n2024-01-08\n194.53\n196.28\n192.67\n196.15\n192.99\n1610600.0\nNaN\n\n\n194371\nZTS\nZoetis Inc. Class A Common Stock\n2024-01-05\n193.07\n195.94\n193.07\n194.85\n191.71\n1088200.0\nNaN\n\n\n194372\nZTS\nZoetis Inc. Class A Common Stock\n2024-01-04\n192.85\n194.93\n192.01\n194.04\n190.91\n1851900.0\nNaN\n\n\n194373\nZTS\nZoetis Inc. Class A Common Stock\n2024-01-03\n195.92\n195.95\n192.80\n192.93\n189.82\n1493000.0\nNaN\n\n\n194374\nZTS\nZoetis Inc. Class A Common Stock\n2024-01-02\n195.79\n197.95\n195.05\n196.57\n193.40\n1642300.0\nNaN\n\n\n\n\n194375 rows × 10 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n\n\nData Exploration\n\nHow concerned are companies with reducing their ESG risk?\nTo begin, let’s compare the distribution of Total ESG ratings from the common companies between the two available ESG-related data frames, along with being split by Year:\n\n(\n    sns.histplot(data=esg_2024, x = 'total_esg', kde = True, bins = 25)\n    .set(xlabel=\"Total ESG\", ylabel=\"Count\", title=\"Distribution of Company-Wise Total ESG (2024)\")\n)\n\nfor l in [esg_2024['total_esg'].quantile(0.25), esg_2024['total_esg'].mean() , esg_2024['total_esg'].quantile(0.75)]:\n  plt.axvline(x = l, alpha = 0.75, color = 'orange')\n\nplt.xticks(ticks=[0,5,10,15,20,25,30,35,40,45,50,55])\n\nplt.show()\n\n\n\n\n\n\n\n\n\nesg_common_2025 = esg_2025[esg_2025['Symbol'].isin(esg_2024['Symbol'])].reset_index()\n\n\n(\n    sns.histplot(data=esg_common_2025, x = 'total_esg', kde = True, bins = 25)\n    .set(xlabel=\"Total ESG\", ylabel=\"Count\", title=\"Distribution of Company-Wise Total ESG (2025)\")\n)\n\nfor l in [esg_common_2025['total_esg'].quantile(0.25), esg_common_2025['total_esg'].mean() , esg_common_2025['total_esg'].quantile(0.75)]:\n  plt.axvline(x = l, alpha = 0.75, color = 'orange')\n\nplt.xticks(ticks=[0,5,10,15,20,25,30,35,40,45,50,55])\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.histplot(data = esg_2024[~esg_2024['total_esg'].isna()], x = 'total_esg', kde=True, label = '2024', bins = 25),\nsns.histplot(data = esg_common_2025[~esg_common_2025['total_esg'].isna()], x = 'total_esg', kde=True, label = '2025', bins = 25)\n\nplt.title(\"Distribution of Company-Wise Total ESG\")\nplt.xlabel(\"Total ESG Rating\")\nplt.ylabel(\"Count\")\n\nplt.xticks(ticks=[0,5,10,15,20,25,30,35,40,45,50,55])\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\nFrom this, it can be observed that there hasn’t been a total ESG shift in favor of a higher/lower average. However, from 2024 to 2025 the distribution of ESG ratings has normalized slightly, dispersing the higher concentration of values surrounding the mean in 2024 more towards the ends of the distribution that reflects movement towards a lower risk overall, though it isn’t significant.\nTo get a better idea of what caused this dispersion, let’s look at the distributions of the individual parts that make up the Total ESG rating:\n\nsns.histplot(data = esg_2024[~esg_2024['Environmental'].isna()], x = 'Environmental', kde=True, label = '2024', bins = 30),\nsns.histplot(data = esg_common_2025[~esg_common_2025['Environmental'].isna()], x = 'Environmental', kde=True, label = '2025', bins = 30)\n\nplt.title(\"Environmental Risk Distribution 2024-2025\")\nplt.xlabel(\"'Environmental' Score\")\nplt.ylabel(\"Count\")\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.histplot(data = esg_2024[~esg_2024['Social'].isna()], x = 'Social', kde=True, label = '2024', bins = 30),\nsns.histplot(data = esg_common_2025[~esg_common_2025['Social'].isna()], x = 'Social', kde=True, label = '2025', bins = 30)\n\nplt.title(\"Social Risk Distribution 2024-2025\")\nplt.xlabel(\"'Social' Score\")\nplt.ylabel(\"Count\")\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.histplot(data = esg_2024[~esg_2024['Governance'].isna()], x = 'Governance', kde=True, label = '2024', bins = 30),\nsns.histplot(data = esg_common_2025[~esg_common_2025['Governance'].isna()], x = 'Governance', kde=True, label = '2025', bins = 30)\n\nplt.title(\"Governance Risk Distribution 2024-2025\")\nplt.xlabel(\"'Governance' Score\")\nplt.ylabel(\"Count\")\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\nGovernance is the most adjusted attribute, with there being a real shift in the distribution itself by ~1.25 points in favor of a lower risk, rather than the values being merely redistributed. This tells us that companies have generally been making efforts to refine/redefine their structures, public transparency, and/or stockholder rights.\nThis is likely due to the 2024 amendment to the ESG by Morningstar to incorporate issues relating to material usage (such as water or raw materials) as a contributor to a lacking corporate governance structure, urging companies to find ways to limit material waste in addition to its existing effect in reducing Environmental risk as well.\nLooking at the Environmental distribution, though, we see that this combined effect isn’t received in the same way, with the amount of companies within the low/medium ranks increasing rather than the average decreasing in the same way as Governance did.\nOne explanation for this could be that there was a reallocation of weights for waste management between the two ratings when the 2024 update occurred, causing the Environmental rating to increase while not being a drastic change as a result of waste management already being a factor, albeit possibly weighted less heavily. For Governance, the waste management parameter was a new addition, so the change would have ended up being more fundamental.\n\n\nWhich Sectors / Industries Typically have the Highest ESG Ratings?\n\n# which industries typically have the highest ESG ratings?\n\nmean_esg_2025 = (\n    esg_2025\n    .groupby(['Sector', 'Industry'])\n    .agg(esg_mean = ('total_esg', 'mean'),\n         esg_std = ('total_esg', 'std'))\n    .dropna()\n    .reset_index()\n)\n\nmean_esg_2025.sort_values('esg_mean', ascending=False)\n\n\n  \n    \n\n\n\n\n\n\nSector\nIndustry\nesg_mean\nesg_std\n\n\n\n\n65\nEnergy\nCoal Mining\n51.025000\n8.421698\n\n\n115\nIndustrials\nFarming/Seeds/Milling\n40.575000\n6.584515\n\n\n1\nBasic Materials\nMetal Mining\n39.956250\n9.653046\n\n\n68\nEnergy\nIntegrated oil Companies\n39.407143\n7.042996\n\n\n70\nEnergy\nOil & Gas Production\n39.156250\n11.617241\n\n\n...\n...\n...\n...\n...\n\n\n12\nConsumer Discretionary\nBooks\n13.550000\n2.050610\n\n\n36\nConsumer Discretionary\nMotor Vehicles\n13.425000\n2.227667\n\n\n38\nConsumer Discretionary\nNewspapers/Magazines\n12.600000\n2.501999\n\n\n46\nConsumer Discretionary\nPublishing\n12.100000\n4.667333\n\n\n39\nConsumer Discretionary\nOffice Equipment/Supplies/Services\n8.775000\n3.031364\n\n\n\n\n166 rows × 4 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\n# Relationship between mean esg and mean esg std deviation; higher mean = higher variance\n\nsns.lmplot(data = mean_esg_2025, x = 'esg_mean', y = 'esg_std')\n\nplt.title(\"Industry Avg. ESG & Std Deviation 2025\")\nplt.xlabel(\"Average Total ESG\")\nplt.ylabel(\"ESG Standard Deviation\")\n\nplt.show()\n\n\n\n\n\n\n\n\nThe prevailing observation here is that there is a strong positive correlation between average ESG and standard deviation. This implies that as ESG ratings become larger, the range between ratings becomes wider in turn, additionally showing that higher ratings among industry peers are less likely to stick as the norm.\nMore industries/companies are coming to the consensus that a lower ESG score is in their best interests, but is this a financial interest or a public relations interest?\n\n\nDo ESG Scores Affect Stock Price?\nTo attempt to answer this question, a possible method could be to plot the relationship between a company’s change in ESG rating and its average stock price. However, this could cause outliers during visualization, beacuse some stocks are valued much higher than others. Instead, I decided to compare the difference in ESG to the average % change of the Adjusted Closing price of a company’s stock, that way the change is more normalized.\nTaking a small random sample from the companies with significant differences in ESG scores, we can start to narrow down the nature of this relationship.\n\ndef rand_sample(n, start, end, seed):\n  random.seed(seed)\n  return random.sample(range(start, end), n)\n\n\n# Example\n\nrand_sample(15, 100, 300, 10)\n  # A sample of 15 numbers from 100-300, with a set seed of '10'\n\n[246, 108, 209, 223, 247, 103, 152, 218, 225, 171, 267, 141, 233, 183, 119]\n\n\n\nesg_diff = pd.DataFrame()\nesg_diff['Symbol'] = esg_2024['Symbol']\nesg_diff['Difference'] = esg_common_2025['total_esg'] - esg_2024['total_esg']\n\nseed = 100\n\nesg_diff_pos = (\n    esg_diff\n    .query(\"Difference &gt; 1 & Difference &lt; 2\")\n    .reset_index(drop=True)\n    .loc[rand_sample(20, 0, esg_diff.query(\"Difference &gt; 1 & Difference &lt; 2\").shape[0]-1, seed)]\n    .reset_index(drop=True)\n)\n\nesg_diff_neg = (\n    esg_diff\n    .query(\"Difference &lt; -1 & Difference &gt; -2\")\n    .reset_index(drop=True)\n    .loc[rand_sample(20, 0, esg_diff.query(\"Difference &lt; -1 & Difference &gt; -2\").shape[0]-1, seed)]\n    .reset_index(drop=True)\n)\n\n\nstocks['adj_pct_change'] = (\n    stocks.groupby('Symbol')['Adj. Close']\n    .transform(lambda x: (x.shift(-1) - x) / x * 100)\n    .shift(1)\n)\n\nstocks[['Name', 'Adj. Close', 'adj_pct_change']]\n\n\n  \n    \n\n\n\n\n\n\nName\nAdj. Close\nadj_pct_change\n\n\n\n\n0\nAgilent Technologies Inc. Common Stock\n116.44\nNaN\n\n\n1\nAgilent Technologies Inc. Common Stock\n118.72\n1.958090\n\n\n2\nAgilent Technologies Inc. Common Stock\n119.65\n0.783356\n\n\n3\nAgilent Technologies Inc. Common Stock\n120.25\n0.501463\n\n\n4\nAgilent Technologies Inc. Common Stock\n121.71\n1.214137\n\n\n...\n...\n...\n...\n\n\n194370\nZoetis Inc. Class A Common Stock\n192.99\n0.108932\n\n\n194371\nZoetis Inc. Class A Common Stock\n191.71\n-0.663247\n\n\n194372\nZoetis Inc. Class A Common Stock\n190.91\n-0.417297\n\n\n194373\nZoetis Inc. Class A Common Stock\n189.82\n-0.570950\n\n\n194374\nZoetis Inc. Class A Common Stock\n193.40\n1.885997\n\n\n\n\n194375 rows × 3 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\nesg_diff_pos['avg_adj_change'] = (\n    stocks[stocks['Symbol'].isin(esg_diff_pos['Symbol'])]\n    .groupby('Symbol')['adj_pct_change']\n    .agg('mean')\n    .reset_index(drop=True)\n)\n\nsns.lmplot(data = esg_diff_pos, x = 'Difference', y = 'avg_adj_change')\n\n\n\n\n\n\n\n\n\nesg_diff_neg['avg_adj_change'] = (\n    stocks[stocks['Symbol'].isin(esg_diff_pos['Symbol'])]\n    .groupby('Symbol')['adj_pct_change']\n    .agg('mean')\n    .reset_index(drop=True)\n)\n\nsns.lmplot(data = esg_diff_neg, x = 'Difference', y = 'avg_adj_change')\n\n\n\n\n\n\n\n\nIt appears that there is a trend with there being a large degree of uncertainty for both visualization’s best fit line, which is indicative of there not being a clear relationship between changes in ESG rating and changes in adjusted closing stock price. The two plots reflect two completely different relationships, one where an increase in ESG correlates to negative changes to stock price, and one where an increase in ESG correlates to a more positive change.\nEven with a combination of these data points, the lack of a definitive relationship is clear, indicated by the near horizontal regression line:\n\nesg_diff_comb = pd.concat([esg_diff_pos, esg_diff_neg]).reset_index(drop=True)\nesg_diff_comb['avg_adj_change'] = (\n    stocks[stocks['Symbol'].isin(esg_diff_comb['Symbol'])]\n    .groupby('Symbol')['adj_pct_change']\n    .agg('mean')\n    .reset_index(drop=True)\n)\n\nsns.lmplot(data = esg_diff_comb, x = 'Difference', y = 'avg_adj_change')\n\n\n\n\n\n\n\n\n\nprint(\"Despite this,\", esg_diff.query(\"Difference &lt; 0\")['Difference'].shape[0] / esg_diff['Difference'].shape[0] * 100\n, \"percent of ESG ratings have lowered between 2024 and 2025.\")\n\nDespite this, 63.2 percent of ESG ratings have lowered between 2024 and 2025.\n\n\n\n\n\nConclusion\nIn conclusion, although ESG score metrics impact the public outlook of a company, and are not uncommonly considered during consumer investment decisions, they doesn’t seem to retain much usefulness when it comes to a company’s financial gain/loss from stocks.\nA company’s incentive to decrease their ESG rating likely comes from either the desire to be looked upon favorably in comparison to their peers or from the pressures of having a standardized metric of sustainability that they could possibly be held accountable for. Regardless of the lack of a clear relationship, companies are vying for lower ESG ratings as time goes on, improving their corporate structures and endeavoring to make environmentally sustainable decisions, the importance of which cannot be understated.\nWorks Cited:\n\n“About Us.” Morningstar, Inc., morningstar.com/company/about-us. Accessed 14 May 2025.\nKuh, Thomas. “Voice of the Asset Owner Survey 2024 Quantitative Analysis.” Morningstar Indexes, 23 Sept. 2024, indexes.morningstar.com/insights/analysis/blt435a08d683d95490/voice-of-the-asset-owner-survey-2024-quantitative-analysis. Accessed 14 May 2025.\n“Morningstar Sustainalytics Introduces Significant Enhancements to Its ESG Risk Ratings.” Sustainalytics.Com, 12 June 2024, sustainalytics.com/esg-news/news-details/2024/06/12/morningstar-indexes-introduces-morningstar-sustainalytics-introduces-significant-enhancements-to-its-esg-risk-ratings#.\nYahoo! Finance, Yahoo!, finance.yahoo.com/. Accessed 14 May 2025."
  }
]